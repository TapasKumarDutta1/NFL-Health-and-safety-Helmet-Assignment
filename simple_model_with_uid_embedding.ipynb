{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_with_uid_embedding",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_with_uid_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAeHxBw8EEt",
        "colab_type": "text"
      },
      "source": [
        "Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstQrkXM8Bz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IonOu6819IW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "67e01bc0-3f9e-46cd-de0d-e5b062ab8c60"
      },
      "source": [
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvhOLFro71iv",
        "colab_type": "text"
      },
      "source": [
        "loading drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c2ea6fa8-f7c4-415d-8a36-5ce18f56102d"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZi5I0Va7-Af",
        "colab_type": "text"
      },
      "source": [
        "Loading dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "57c06616-5bc1-4f36-b578-14cae577c2ac"
      },
      "source": [
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train_id.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test_id.csv',index_col=[0])\n",
        "trn.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>C9_std_isna</th>\n",
              "      <th>C10_std_isna</th>\n",
              "      <th>C11_std_isna</th>\n",
              "      <th>C12_std_isna</th>\n",
              "      <th>C13_std_isna</th>\n",
              "      <th>C14_std_isna</th>\n",
              "      <th>D1_mean_isna</th>\n",
              "      <th>D1_std_isna</th>\n",
              "      <th>D2_mean_isna</th>\n",
              "      <th>D2_std_isna</th>\n",
              "      <th>D3_mean_isna</th>\n",
              "      <th>D3_std_isna</th>\n",
              "      <th>D4_mean_isna</th>\n",
              "      <th>D4_std_isna</th>\n",
              "      <th>D5_mean_isna</th>\n",
              "      <th>D5_std_isna</th>\n",
              "      <th>D6_mean_isna</th>\n",
              "      <th>D6_std_isna</th>\n",
              "      <th>D7_mean_isna</th>\n",
              "      <th>D7_std_isna</th>\n",
              "      <th>D8_mean_isna</th>\n",
              "      <th>D8_std_isna</th>\n",
              "      <th>D9_mean_isna</th>\n",
              "      <th>D9_std_isna</th>\n",
              "      <th>D10_mean_isna</th>\n",
              "      <th>D10_std_isna</th>\n",
              "      <th>D11_mean_isna</th>\n",
              "      <th>D11_std_isna</th>\n",
              "      <th>D12_mean_isna</th>\n",
              "      <th>D12_std_isna</th>\n",
              "      <th>D13_mean_isna</th>\n",
              "      <th>D13_std_isna</th>\n",
              "      <th>D14_mean_isna</th>\n",
              "      <th>D14_std_isna</th>\n",
              "      <th>D15_mean_isna</th>\n",
              "      <th>D15_std_isna</th>\n",
              "      <th>V1_mean_isna</th>\n",
              "      <th>V1_std_isna</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wnan315.013926-13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wgmail.com325.027551.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Woutlook.com330.046631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wyahoo.com476.018132-111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hgmail.com420.044971.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 619 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2  ...  V1_std_isna  isFraud                          id\n",
              "0  1.0  0.0  0.0  ...            1        0         Wnan315.013926-13.0\n",
              "1  1.0  0.0  0.0  ...            1        0      Wgmail.com325.027551.0\n",
              "2  1.0  0.0  0.0  ...            0        0    Woutlook.com330.046631.0\n",
              "3  1.0  0.0  0.0  ...            1        0  Wyahoo.com476.018132-111.0\n",
              "4  0.0  0.0  0.0  ...            1        0      Hgmail.com420.044971.0\n",
              "\n",
              "[5 rows x 619 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEIUFVW8iAC",
        "colab_type": "text"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ce438c87-5acf-4b98-a7d3-0462deab69db"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2793.39 MB\n",
            "Memory usage after optimization is: 678.37 MB\n",
            "Decreased by 75.7%\n",
            "Memory usage of dataframe is 2392.90 MB\n",
            "Memory usage after optimization is: 580.09 MB\n",
            "Decreased by 75.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjn9ePhArDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.replace([np.inf,-np.inf],np.nan)\n",
        "tst=tst.replace([np.inf,-np.inf],np.nan)\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRqrD6vz8ol6",
        "colab_type": "text"
      },
      "source": [
        "Making the callbacks and loading model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dk={}\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data,epochs):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "        self.epochs=epochs\n",
        "        self.val=0\n",
        "        self.wts=[]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        if roc_val>self.val:\n",
        "          self.val=roc_val\n",
        "          self.epoch=10\n",
        "          self.wts=self.model.get_weights()\n",
        "        else:\n",
        "          self.epoch-=1\n",
        "        if self.epoch==0:\n",
        "          self.model.set_weights(self.wts)\n",
        "          self.model.stop_training = True\n",
        "        print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model(dim):\n",
        "  K.clear_session()\n",
        "\n",
        "\n",
        "  uid=Input((1,))\n",
        "  inp=Input((873,))\n",
        "  emb=Embedding(input_dim=dim,output_dim=4)(uid)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Concatenate()([emb,x])\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=[inp,uid],outputs=x)\n",
        "  return mod\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZH6xEokzPfj",
        "colab_type": "text"
      },
      "source": [
        "Adding all datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZw0LXIzPG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "b783a6bb-9490-4acf-a102-93a58d4b1956"
      },
      "source": [
        "trn_s=trn.shape[0]\n",
        "df=pd.concat([trn,tst],0).reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "autoenc=pd.read_csv('/content/gdrive/My Drive/fraud/without_id.csv',index_col=[0])\n",
        "autoenc=reduce_mem_usage(autoenc)\n",
        "\n",
        "autoenc.columns=[i for i in range(444,444+autoenc.shape[1])]\n",
        "\n",
        "\n",
        "df=pd.concat([df,autoenc],1)\n",
        "del([autoenc])\n",
        "gc.collect()\n",
        "\n",
        "trn=df.loc[:trn_s-1]\n",
        "tst=df.loc[trn_s:].reset_index(drop=True)\n",
        "del([df])\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2151.40 MB\n",
            "Memory usage after optimization is: 544.13 MB\n",
            "Decreased by 74.7%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxmq8JSOz6Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical=[str(i) for i in range(444)]\n",
        "trn[categorical]=trn[categorical].astype('uint8')\n",
        "tst[categorical]=tst[categorical].astype('uint8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oor5OujA6Bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec9c383d-b6c8-4fd7-f86b-176f4d591c6a"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "splits=KFold(n_splits=5)\n",
        "gc.collect()\n",
        "pre=np.zeros((506691,1))\n",
        "tst=tst.drop(['isFraud'],1)\n",
        "for train_index,test_index in tqdm(splits.split(trn)):\n",
        "  X_train, X_test = trn.loc[train_index], trn.loc[test_index]\n",
        "  y_train, y_test = X_train['isFraud'], X_test['isFraud']\n",
        "  ids={}\n",
        "  for en,id in enumerate(X_train['id'].unique()):\n",
        "    ids[id]=en+2\n",
        "  X_train['id']=X_train['id'].map(lambda x: ids.get(x,1))\n",
        "  X_test['id']=X_test['id'].map(lambda x: ids.get(x,1))\n",
        "  dim=X_train['id'].nunique()+2\n",
        "  gc.collect()\n",
        "  trn_id,tst_id=X_train['id'],X_test['id']\n",
        "  X_train=X_train.drop(['isFraud','id'],1)\n",
        "  X_test=X_test.drop(['isFraud','id'],1)\n",
        "  mod=load_model(dim)\n",
        "  roc = RocCallback(validation_data=([X_test,tst_id], y_test),epochs=10)\n",
        "  mod.compile(optimizer=Nadam(),loss='binary_crossentropy')\n",
        "  es=EarlyStopping(monitor='acu_val',min_delta=0.0001,mode='min',restore_best_weights=True,patience=10)\n",
        "  mod.fit([X_train,trn_id],y_train,validation_data=([X_test,tst_id],y_test),batch_size=2048,epochs=50,callbacks=[roc])\n",
        "  \n",
        "  del[(X_train,y_train)]\n",
        "  gc.collect()\n",
        "\n",
        "  mod.fit([X_test,tst_id],y_test,epochs=2,batch_size=2048)\n",
        "  pre+=mod.predict([tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))])/5\n",
        "  \n",
        "  del([X_test,y_test,mod])\n",
        "  gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.1322roc-auc_val: 0.8704\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.1320 - val_loss: 0.0871\n",
            "Epoch 2/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0906roc-auc_val: 0.8824\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0904 - val_loss: 0.0785\n",
            "Epoch 3/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0777roc-auc_val: 0.8826\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0776 - val_loss: 0.0778\n",
            "Epoch 4/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0670roc-auc_val: 0.8976\n",
            "231/231 [==============================] - 8s 33ms/step - loss: 0.0670 - val_loss: 0.0824\n",
            "Epoch 5/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0576roc-auc_val: 0.9154\n",
            "231/231 [==============================] - 8s 33ms/step - loss: 0.0576 - val_loss: 0.0747\n",
            "Epoch 6/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0501roc-auc_val: 0.9166\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0502 - val_loss: 0.0712\n",
            "Epoch 7/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0436roc-auc_val: 0.911\n",
            "231/231 [==============================] - 8s 33ms/step - loss: 0.0435 - val_loss: 0.0754\n",
            "Epoch 8/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0384roc-auc_val: 0.9025\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0384 - val_loss: 0.0812\n",
            "Epoch 9/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0336roc-auc_val: 0.9117\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0336 - val_loss: 0.0774\n",
            "Epoch 10/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0299roc-auc_val: 0.9195\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.0299 - val_loss: 0.0763\n",
            "Epoch 11/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0262roc-auc_val: 0.9116\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0262 - val_loss: 0.0796\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0232roc-auc_val: 0.9053\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0232 - val_loss: 0.0821\n",
            "Epoch 13/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0206roc-auc_val: 0.9073\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0206 - val_loss: 0.1008\n",
            "Epoch 14/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0185roc-auc_val: 0.9108\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0185 - val_loss: 0.0832\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0167roc-auc_val: 0.9091\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0167 - val_loss: 0.0858\n",
            "Epoch 16/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0151roc-auc_val: 0.909\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0151 - val_loss: 0.0978\n",
            "Epoch 17/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0137roc-auc_val: 0.9089\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.0137 - val_loss: 0.0842\n",
            "Epoch 18/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0125roc-auc_val: 0.9148\n",
            "231/231 [==============================] - 8s 36ms/step - loss: 0.0125 - val_loss: 0.0813\n",
            "Epoch 19/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0115roc-auc_val: 0.9037\n",
            "231/231 [==============================] - 9s 39ms/step - loss: 0.0115 - val_loss: 0.0909\n",
            "Epoch 20/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0104roc-auc_val: 0.9055\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0104 - val_loss: 0.0849\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0595\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [03:04, 184.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.1107roc-auc_val: 0.9042\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.1106 - val_loss: 0.1014\n",
            "Epoch 2/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0832roc-auc_val: 0.9154\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0831 - val_loss: 0.0940\n",
            "Epoch 3/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0724roc-auc_val: 0.9285\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0723 - val_loss: 0.0895\n",
            "Epoch 4/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0631roc-auc_val: 0.9329\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0631 - val_loss: 0.0878\n",
            "Epoch 5/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0545roc-auc_val: 0.9366\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0544 - val_loss: 0.0852\n",
            "Epoch 6/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0476roc-auc_val: 0.9393\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0475 - val_loss: 0.0799\n",
            "Epoch 7/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0414roc-auc_val: 0.9407\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0414 - val_loss: 0.0789\n",
            "Epoch 8/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0361roc-auc_val: 0.9451\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0362 - val_loss: 0.0786\n",
            "Epoch 9/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0319roc-auc_val: 0.9368\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0319 - val_loss: 0.0808\n",
            "Epoch 10/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0280roc-auc_val: 0.9435\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0279 - val_loss: 0.0794\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0248roc-auc_val: 0.9388\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0248 - val_loss: 0.0784\n",
            "Epoch 12/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0222roc-auc_val: 0.9464\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0221 - val_loss: 0.0766\n",
            "Epoch 13/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0197roc-auc_val: 0.9436\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0197 - val_loss: 0.0804\n",
            "Epoch 14/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0178roc-auc_val: 0.9416\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0179 - val_loss: 0.0794\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0160roc-auc_val: 0.9406\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0160 - val_loss: 0.0796\n",
            "Epoch 16/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0144roc-auc_val: 0.9385\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0144 - val_loss: 0.0819\n",
            "Epoch 17/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0131roc-auc_val: 0.9413\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0131 - val_loss: 0.0814\n",
            "Epoch 18/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0118roc-auc_val: 0.9433\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0118 - val_loss: 0.0794\n",
            "Epoch 19/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0108roc-auc_val: 0.937\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0108 - val_loss: 0.0816\n",
            "Epoch 20/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0099roc-auc_val: 0.9421\n",
            "231/231 [==============================] - 8s 36ms/step - loss: 0.0100 - val_loss: 0.0810\n",
            "Epoch 21/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0093roc-auc_val: 0.9383\n",
            "231/231 [==============================] - 8s 36ms/step - loss: 0.0093 - val_loss: 0.0847\n",
            "Epoch 22/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0086roc-auc_val: 0.9376\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0086 - val_loss: 0.0833\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0694\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r2it [06:14, 185.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.1225roc-auc_val: 0.8918\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.1222 - val_loss: 0.0998\n",
            "Epoch 2/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0853roc-auc_val: 0.9012\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0852 - val_loss: 0.1021\n",
            "Epoch 3/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0738roc-auc_val: 0.9174\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0738 - val_loss: 0.0920\n",
            "Epoch 4/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0644roc-auc_val: 0.9292\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0643 - val_loss: 0.0849\n",
            "Epoch 5/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0564roc-auc_val: 0.9317\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0564 - val_loss: 0.0823\n",
            "Epoch 6/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0489roc-auc_val: 0.9337\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0490 - val_loss: 0.0796\n",
            "Epoch 7/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0425roc-auc_val: 0.9372\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0424 - val_loss: 0.0794\n",
            "Epoch 8/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0374roc-auc_val: 0.9349\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0374 - val_loss: 0.0772\n",
            "Epoch 9/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0328roc-auc_val: 0.9375\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0328 - val_loss: 0.0771\n",
            "Epoch 10/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0293roc-auc_val: 0.94\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0292 - val_loss: 0.0759\n",
            "Epoch 11/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0259roc-auc_val: 0.9409\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0259 - val_loss: 0.0763\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0229roc-auc_val: 0.9377\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.0229 - val_loss: 0.0765\n",
            "Epoch 13/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0204roc-auc_val: 0.9373\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0204 - val_loss: 0.0783\n",
            "Epoch 14/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0184roc-auc_val: 0.9392\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0184 - val_loss: 0.0760\n",
            "Epoch 15/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0164roc-auc_val: 0.9359\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0165 - val_loss: 0.0782\n",
            "Epoch 16/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0149roc-auc_val: 0.9365\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0149 - val_loss: 0.0768\n",
            "Epoch 17/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0137roc-auc_val: 0.939\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0137 - val_loss: 0.0783\n",
            "Epoch 18/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0123roc-auc_val: 0.9344\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0123 - val_loss: 0.0784\n",
            "Epoch 19/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0114roc-auc_val: 0.9351\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0114 - val_loss: 0.0792\n",
            "Epoch 20/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0104roc-auc_val: 0.9386\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0104 - val_loss: 0.0766\n",
            "Epoch 21/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0094roc-auc_val: 0.9355\n",
            "231/231 [==============================] - 8s 33ms/step - loss: 0.0094 - val_loss: 0.0809\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0670\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r3it [09:16, 184.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.1099roc-auc_val: 0.908\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.1099 - val_loss: 0.0991\n",
            "Epoch 2/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0844roc-auc_val: 0.9271\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0844 - val_loss: 0.0881\n",
            "Epoch 3/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0733roc-auc_val: 0.9355\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0733 - val_loss: 0.0857\n",
            "Epoch 4/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0641roc-auc_val: 0.9417\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0640 - val_loss: 0.0815\n",
            "Epoch 5/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0556roc-auc_val: 0.9489\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0556 - val_loss: 0.0774\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0485roc-auc_val: 0.9535\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0485 - val_loss: 0.0746\n",
            "Epoch 7/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0424roc-auc_val: 0.9545\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0424 - val_loss: 0.0730\n",
            "Epoch 8/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0371roc-auc_val: 0.9549\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0371 - val_loss: 0.0725\n",
            "Epoch 9/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0324roc-auc_val: 0.9579\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0324 - val_loss: 0.0709\n",
            "Epoch 10/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0287roc-auc_val: 0.9569\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0287 - val_loss: 0.0714\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0255roc-auc_val: 0.9579\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0255 - val_loss: 0.0701\n",
            "Epoch 12/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0224roc-auc_val: 0.9571\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0224 - val_loss: 0.0698\n",
            "Epoch 13/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0202roc-auc_val: 0.9552\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0202 - val_loss: 0.0719\n",
            "Epoch 14/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0180roc-auc_val: 0.9568\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0180 - val_loss: 0.0695\n",
            "Epoch 15/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0162roc-auc_val: 0.9537\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0162 - val_loss: 0.0715\n",
            "Epoch 16/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0146roc-auc_val: 0.9577\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0146 - val_loss: 0.0711\n",
            "Epoch 17/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0131roc-auc_val: 0.9539\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0131 - val_loss: 0.0730\n",
            "Epoch 18/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0120roc-auc_val: 0.9578\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0120 - val_loss: 0.0700\n",
            "Epoch 19/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0109roc-auc_val: 0.9534\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0109 - val_loss: 0.0733\n",
            "Epoch 20/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0101roc-auc_val: 0.9566\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0101 - val_loss: 0.0706\n",
            "Epoch 21/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0092roc-auc_val: 0.9549\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0092 - val_loss: 0.0718\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0662\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r4it [12:16, 183.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.1205roc-auc_val: 0.889\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.1205 - val_loss: 0.0977\n",
            "Epoch 2/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0857roc-auc_val: 0.9005\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0857 - val_loss: 0.0955\n",
            "Epoch 3/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0739roc-auc_val: 0.9026\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0739 - val_loss: 0.0934\n",
            "Epoch 4/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0645roc-auc_val: 0.9156\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0645 - val_loss: 0.0903\n",
            "Epoch 5/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0560roc-auc_val: 0.9183\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.0560 - val_loss: 0.0916\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0486roc-auc_val: 0.9238\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0486 - val_loss: 0.0899\n",
            "Epoch 7/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0426roc-auc_val: 0.9217\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0426 - val_loss: 0.0876\n",
            "Epoch 8/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0373roc-auc_val: 0.9229\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0372 - val_loss: 0.0869\n",
            "Epoch 9/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0327roc-auc_val: 0.9289\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0327 - val_loss: 0.0863\n",
            "Epoch 10/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0289roc-auc_val: 0.9207\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0289 - val_loss: 0.0865\n",
            "Epoch 11/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0256roc-auc_val: 0.9262\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0256 - val_loss: 0.0860\n",
            "Epoch 12/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0228roc-auc_val: 0.9281\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0228 - val_loss: 0.0854\n",
            "Epoch 13/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0202roc-auc_val: 0.9218\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0202 - val_loss: 0.0874\n",
            "Epoch 14/50\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0183roc-auc_val: 0.9275\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0182 - val_loss: 0.0875\n",
            "Epoch 15/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0166roc-auc_val: 0.9187\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0166 - val_loss: 0.0887\n",
            "Epoch 16/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0149roc-auc_val: 0.9224\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0149 - val_loss: 0.0874\n",
            "Epoch 17/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0134roc-auc_val: 0.932\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0135 - val_loss: 0.0881\n",
            "Epoch 18/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0123roc-auc_val: 0.9241\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0123 - val_loss: 0.0912\n",
            "Epoch 19/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0112roc-auc_val: 0.924\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0112 - val_loss: 0.0948\n",
            "Epoch 20/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0103roc-auc_val: 0.9185\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0104 - val_loss: 0.0897\n",
            "Epoch 21/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0094roc-auc_val: 0.9227\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0094 - val_loss: 0.0911\n",
            "Epoch 22/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0089roc-auc_val: 0.9253\n",
            "231/231 [==============================] - 8s 33ms/step - loss: 0.0089 - val_loss: 0.0883\n",
            "Epoch 23/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0083roc-auc_val: 0.9271\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0083 - val_loss: 0.0948\n",
            "Epoch 24/50\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0077roc-auc_val: 0.9226\n",
            "231/231 [==============================] - 8s 37ms/step - loss: 0.0077 - val_loss: 0.0930\n",
            "Epoch 25/50\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0071roc-auc_val: 0.9273\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0071 - val_loss: 0.0907\n",
            "Epoch 26/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0068roc-auc_val: 0.9255\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 0.0068 - val_loss: 0.0944\n",
            "Epoch 27/50\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0064roc-auc_val: 0.9275\n",
            "231/231 [==============================] - 9s 39ms/step - loss: 0.0064 - val_loss: 0.0901\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0701\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5it [16:05, 193.02s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYgkVd5_NVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "805f459d-2642-4d71-b11c-5465dcd1487d"
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv.zip')\n",
        "sub['isFraud']=pre.ravel()\n",
        "sub=sub.set_index('TransactionID')\n",
        "sub.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.000719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.000042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.003829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.000410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.000719\n",
              "3663550        0.000042\n",
              "3663551        0.003829\n",
              "3663552        0.000410\n",
              "3663553        0.000033"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZlw01oHayo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('sub.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FeqwiR2HcSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "f163a71c-a882-463a-ff62-8000ad4fc81f"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd7c834390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeWMkwJIWng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}