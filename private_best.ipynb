{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "private_best.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1SelwvLcYe/fmOodEVtaC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/NFL-Health-and-safety-Helmet-Assignment/blob/master/private_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PROyI9asVrUV"
      },
      "source": [
        "# Install helmet-assignment helper code\n",
        "!pip install ../input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\n",
        "from helmet_assignment.score import NFLAssignmentScorer, check_submission\n",
        "from helmet_assignment.features import add_track_features\n",
        "from helmet_assignment.video import video_with_predictions\n",
        "from IPython.display import Video, display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfopVy-OW6Ud"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import cv2\n",
        "import traceback\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "from multiprocessing import Pool\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import torchvision\n",
        "import shutil\n",
        "from joblib import Parallel, delayed\n",
        "from scipy.spatial.transform import Rotation\n",
        "from math import pi, ceil, sqrt\n",
        "from scipy.spatial import distance_matrix\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from statistics import mode\n",
        "from sklearn.cluster import k_means\n",
        "import importlib.util\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaokNfDGW6ON"
      },
      "source": [
        "n_test_videos = len(os.listdir('../input/nfl-health-and-safety-helmet-assignment/test/'))\n",
        "# Run in debug mode unless during submission\n",
        "if n_test_videos == 6:\n",
        "    debug = True\n",
        "else:\n",
        "    debug = False\n",
        "# Configurables\n",
        "n_debug_samples = 1\n",
        "RANDOM_STATE = 42\n",
        "CONF_THRE = 0.4\n",
        "max_iter = 1000\n",
        "DIG_STEP = 3\n",
        "DIG_MAX = DIG_STEP*10\n",
        "\n",
        "# Read in the data.\n",
        "\n",
        "BASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\n",
        "\n",
        "labels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\n",
        "if debug:\n",
        "    tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n",
        "    helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\n",
        "else:\n",
        "    tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n",
        "    helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n",
        "helmets['frame'] = helmets.video_frame.apply(lambda x: int(x.split('_')[-1]))    \n",
        "tracking = add_track_features(tracking)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VahW7NvgW6K0"
      },
      "source": [
        "def add_cols(df):\n",
        "    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n",
        "    if 'video' not in df.columns:\n",
        "        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n",
        "    return df\n",
        "helmets = add_cols(helmets)\n",
        "if debug:\n",
        "    labels = add_cols(labels)\n",
        "    # Select `n_debug_samples` worth of videos to debug with\n",
        "    sample_videos = labels['video'].drop_duplicates() \\\n",
        "        .sample(n_debug_samples, random_state=RANDOM_STATE).tolist()\n",
        "    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n",
        "    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n",
        "    helmets = helmets[helmets['video'].isin(sample_videos)]\n",
        "    labels = labels[labels['video'].isin(sample_videos)]\n",
        "tracking.shape, helmets.shape, labels.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8IjOt8bW6HO"
      },
      "source": [
        "def find_nearest(tracking, value):\n",
        "    value = int(value)\n",
        "    array = np.asarray(tracking['est_frame']).astype(int)\n",
        "    unique_frames = np.unique(array)\n",
        "    idx = np.argmin(np.abs(unique_frames - value))\n",
        "    if value > unique_frames[idx]:\n",
        "        curr_frame = tracking[tracking['est_frame'] == unique_frames[idx]]\n",
        "        try:\n",
        "            next_frame = tracking[\n",
        "                    tracking['est_frame'] == unique_frames[idx + 1]]\n",
        "        except IndexError:\n",
        "            return curr_frame\n",
        "\n",
        "    elif value < unique_frames[idx]:\n",
        "        next_frame = tracking[tracking['est_frame'] == unique_frames[idx]]\n",
        "        try:\n",
        "            curr_frame = tracking[\n",
        "                tracking['est_frame'] == unique_frames[idx - 1]]\n",
        "        except IndexError:\n",
        "            return next_frame\n",
        "        \n",
        "    else:\n",
        "        return tracking[tracking['est_frame'] == unique_frames[idx]].reset_index(drop=True)\n",
        "    try:\n",
        "        next_frame = next_frame.set_index('player')\n",
        "        curr_frame = curr_frame.set_index('player')\n",
        "\n",
        "        diff = next_frame.est_frame.iloc[0] - curr_frame.est_frame.iloc[0]\n",
        "        cols = ['x','y', 'a', 'dir', 's', 'o', 'est_frame']\n",
        "        if diff != 0:\n",
        "            speed = (next_frame[cols] - curr_frame[cols]) / diff\n",
        "        else:\n",
        "            speed = 0\n",
        "        ret = next_frame.copy()\n",
        "        ret[cols] = curr_frame[cols] + (value - curr_frame.est_frame.iloc[0]) * speed\n",
        "        ret = ret.dropna(axis=0, subset=['est_frame'])\n",
        "        ret['est_frame'] = ret['est_frame'].astype(int)\n",
        "    except:\n",
        "        print(next_frame)\n",
        "        print(curr_frame)\n",
        "        print(ret['est_frame'])\n",
        "        raise\n",
        "    return ret.reset_index()\n",
        "\n",
        "\n",
        "def norm_arr(a):\n",
        "    a = a-a.min()\n",
        "    a = a/a.max()\n",
        "    return a\n",
        "    \n",
        "def dist(a1, a2):\n",
        "    return np.linalg.norm(a1-a2)\n",
        "\n",
        "def dist_for_different_len(a1, a2):\n",
        "    assert len(a1) >= len(a2), f'{len(a1)}, {len(a2)}'\n",
        "    len_diff = len(a1) - len(a2)\n",
        "#     a2 = norm_arr(a2)\n",
        "    if len_diff == 0:\n",
        "#         a1 = norm_arr(a1)\n",
        "        return dist(a1,a2), ()\n",
        "    else:\n",
        "        min_dist = 10000\n",
        "        min_detete_idx = None\n",
        "        cnt = 0\n",
        "        del_list = list(itertools.combinations(range(len(a1)),len_diff))\n",
        "        if len(del_list) > max_iter:\n",
        "            del_list = random.sample(del_list, max_iter)\n",
        "        for detete_idx in del_list:\n",
        "            this_a1 = np.delete(a1, detete_idx)\n",
        "#             this_a1 = norm_arr(this_a1)\n",
        "            this_dist = dist(this_a1, a2)\n",
        "            #print(len(a1), len(a2), this_dist)\n",
        "            if min_dist > this_dist:\n",
        "                min_dist = this_dist\n",
        "                min_detete_idx = detete_idx\n",
        "                \n",
        "        return min_dist, min_detete_idx\n",
        "        \n",
        "def rotate_arr(u, t, deg=True):\n",
        "    if deg == True:\n",
        "        t = np.deg2rad(t)\n",
        "    R = np.array([[np.cos(t), -np.sin(t)],\n",
        "                  [np.sin(t),  np.cos(t)]])\n",
        "    return  np.dot(R, u)\n",
        "\n",
        "def dist_rot(tracking_df, a2):\n",
        "    tracking_df = tracking_df.sort_values('x')\n",
        "    x = tracking_df['x']\n",
        "    y = tracking_df['y']\n",
        "    min_dist = 10000\n",
        "    min_idx = None\n",
        "    min_x = None\n",
        "    for dig in range(-DIG_MAX,DIG_MAX+1,DIG_STEP):\n",
        "        arr = rotate_arr(np.array((x,y)), dig)\n",
        "        this_dist, this_idx = dist_for_different_len(np.sort(arr[0]), a2)\n",
        "        if min_dist > this_dist:\n",
        "            min_dist = this_dist\n",
        "            min_idx = this_idx\n",
        "            min_x = arr[0]\n",
        "    tracking_df['x_rot'] = min_x\n",
        "    player_arr = tracking_df.sort_values('x_rot')['player'].values\n",
        "    players = np.delete(player_arr,min_idx)\n",
        "    return min_dist, players\n",
        "\n",
        "def dist_matrix(points, dense_view=True):\n",
        "    z = np.array([complex(c[0], c[1]) for c in points])\n",
        "    if dense_view:\n",
        "        return np.abs(z[..., np.newaxis] - z)[np.triu_indices(len(z),1)]\n",
        "    else:\n",
        "        return np.abs(z[..., np.newaxis] - z)\n",
        "def mapping_df_fallback(tracking, df, previous_mapped=None):\n",
        "    gameKey,playID,view,frame = df.video_frame.iloc[0].split('_')\n",
        "    gameKey = int(gameKey)\n",
        "    playID = int(playID)\n",
        "    frame = int(frame)\n",
        "    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)]\n",
        "    this_tracking = find_nearest(this_tracking, frame)\n",
        "    len_this_tracking = len(this_tracking)\n",
        "    df['center_h_p'] = (df['left']+df['width']/2).astype(int)\n",
        "    df['center_h_m'] = (df['left']+df['width']/2).astype(int)*-1\n",
        "    if 'conf' in df.columns:\n",
        "        df = df[df['conf']>CONF_THRE].copy()\n",
        "    if len(df) > len_this_tracking:\n",
        "        df = df.tail(len_this_tracking)\n",
        "    df_p = df.sort_values('center_h_p').copy()\n",
        "    df_m = df.sort_values('center_h_m').copy()\n",
        "    \n",
        "    if view == 'Endzone':\n",
        "        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n",
        "    a2_p = df_p['center_h_p'].values\n",
        "    a2_m = df_m['center_h_m'].values\n",
        "\n",
        "    min_dist_p, min_detete_idx_p = dist_rot(this_tracking ,a2_p)\n",
        "    min_dist_m, min_detete_idx_m = dist_rot(this_tracking ,a2_m)\n",
        "    if min_dist_p < min_dist_m:\n",
        "        min_dist = min_dist_p\n",
        "        min_detete_idx = min_detete_idx_p\n",
        "        tgt_df = df_p\n",
        "    else:\n",
        "        min_dist = min_dist_m\n",
        "        min_detete_idx = min_detete_idx_m\n",
        "        tgt_df = df_m\n",
        "    #print(video_frame, len(this_tracking), len(df), len(df[df['conf']>CONF_THRE]), this_tracking['x'].mean(), min_dist_p, min_dist_m, min_dist)\n",
        "    tgt_df['label'] = min_detete_idx\n",
        "    unmatched = this_tracking[~this_tracking['player'].isin(tgt_df['label'])]\n",
        "    return tgt_df[df.columns.tolist() + ['label']], this_tracking, {'fallback_mapping_used':True}, unmatched\n",
        "from pykalman import KalmanFilter\n",
        "from typing import Dict, Iterable, List\n",
        "from numpy import ma\n",
        "def cartesian_product(arrays):\n",
        "    la = len(arrays)\n",
        "    dtype = np.find_common_type([np.array(a).dtype for a in arrays], [])\n",
        "    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
        "    for i, a in enumerate(np.ix_(*arrays)):\n",
        "        arr[..., i] = a\n",
        "    return arr.reshape(-1, la)\n",
        "\n",
        "\n",
        "def get_observation_matrix(params_len):\n",
        "    return np.pad(np.eye(params_len), ((0,0),(0,2*params_len)))\n",
        "def get_transition_matrix(params_len):\n",
        "    return np.eye(3 * params_len) + np.diag(\n",
        "                    np.ones(2 * params_len), params_len) + np.diag(\n",
        "                    0.5 * np.ones(params_len), 2 * params_len)\n",
        "\n",
        "class KalmanFilterRoutine:\n",
        "    def __init__(self, params: List[str], init_frames=5):\n",
        "        self.init_frames = init_frames\n",
        "        self.kf = None\n",
        "        self.params_buffer = []\n",
        "        self.frame = 0\n",
        "        self.means = None\n",
        "        self.covariances = None\n",
        "        self.observation_matrix = None\n",
        "        self.transition_matrix = None\n",
        "        self.params = params\n",
        "        self.params_len = len(params)\n",
        "\n",
        "    @property\n",
        "    def is_ready(self):\n",
        "        return self.frame >= self.init_frames\n",
        "        \n",
        "    def update(self, **params):\n",
        "        self.frame += 1\n",
        "        if self.frame < self.init_frames:\n",
        "            self.params_buffer.append(params)\n",
        "        else:\n",
        "            if self.frame == self.init_frames:\n",
        "                self.params_buffer.append(params)\n",
        "                self.transition_matrix = get_transition_matrix(self.params_len)\n",
        "                self.observation_matrix = get_observation_matrix(self.params_len)\n",
        "                params_df = pd.DataFrame(self.params_buffer)\n",
        "                missing = [p for p in self.params if p not in params_df.columns]\n",
        "                params_df[missing] = np.nan\n",
        "                params_df = params_df.fillna(0)\n",
        "                params_df = params_df[self.params]\n",
        "                initial_state_mean = np.pad(params_df.mean(axis=0), (\n",
        "                    (0, 2*len(self.params))))\n",
        "                self.kf = KalmanFilter(transition_matrices=self.transition_matrix, \n",
        "                                       observation_matrices=self.observation_matrix,\n",
        "                                      initial_state_mean=initial_state_mean, random_state=RANDOM_STATE)\n",
        "                if len(params_df) < 3:\n",
        "                    params_df = pd.concat(\n",
        "                        [params_df] + [params_df.iloc[[-1]] for _ in range(3 - len(params_df))])\n",
        "                self.means, self.covariances = self.kf.filter(params_df.values)\n",
        "                self.means = self.means.tolist()\n",
        "                self.covariances = self.covariances.tolist()\n",
        "            if self.frame > self.init_frames:\n",
        "                observation = ma.asarray(np.array([params[k] if k in params else np.nan for k  in self.params]))\n",
        "                observation[np.isnan(observation)] = ma.masked\n",
        "                state_means, state_covs = self.kf.filter_update(\n",
        "                    self.means[-1],\n",
        "                    self.covariances[-1],\n",
        "                    observation =observation)\n",
        "                self.means.append(state_means)\n",
        "                self.covariances.append(state_covs)\n",
        "            self.updated_params =  np.array(self.means[-1][:len(self.params)])\n",
        "            self.updated_params_der = np.array(self.means[-1][len(self.params): 2 * len(self.params)])\n",
        "            self.updated_params_sder = np.array(self.means[-1][2 * len(self.params): 3 * len(self.params)])\n",
        "        \n",
        "from collections import deque\n",
        "\n",
        "class ParamsCombinationsGenerator:\n",
        "    # Uses Kalman Filter with Taylor expansion up to the 2nd derivative\n",
        "    def __init__(self, params_ranges : Dict[str, Iterable],\n",
        "                 strictly_positive_params:List[str]=None,\n",
        "                 min_perturbations: Dict[str, float]=None,\n",
        "                 max_perturbations: Dict[str, float]=None,\n",
        "                 kalman_init=5,\n",
        "                 allowed_change_ratio=1, n_steps=5, \n",
        "                 obey_original_ranges=True, use_kalman=True, previous_frames_to_keep=10):\n",
        "        self.use_kalman = use_kalman\n",
        "        self.kalman_init = kalman_init\n",
        "        self.allowed_change_ratio = allowed_change_ratio\n",
        "        self.params_ranges = params_ranges\n",
        "        self.strictly_positive_params = strictly_positive_params\n",
        "        self.n_steps = n_steps\n",
        "        self.previous_frames_to_keep = previous_frames_to_keep\n",
        "        self.buffer_starts = deque(maxlen=previous_frames_to_keep)\n",
        "        self.buffer_ends = deque(maxlen=previous_frames_to_keep)\n",
        "        self.params_buffer = []\n",
        "        self.ori_options = [0, 1]\n",
        "        self.frame = 0\n",
        "        self.params = list(params_ranges.keys())\n",
        "        \n",
        "        self.means = None\n",
        "        self.covariances = None\n",
        "        self.observation_matrix = None\n",
        "        self.transition_matrix = None\n",
        "        self.obey_original_ranges = obey_original_ranges\n",
        "        if obey_original_ranges:\n",
        "            self.ranges_limits = np.array([[np.min(params_ranges[p]),\n",
        "                                            np.max(params_ranges[p])] for p in self.params])\n",
        "        if min_perturbations is None:\n",
        "            self.min_perturbations = np.zeros(len(self.params))\n",
        "        else:\n",
        "            self.min_perturbations = np.array([min_perturbations[x]  if x in min_perturbations else 0 for x in self.params])\n",
        "        if max_perturbations is not None:\n",
        "            self.max_perturbations = np.array([max_perturbations[x]  if x in max_perturbations else\n",
        "                                               np.inf for x in self.params])\n",
        "        else:\n",
        "            self.max_perturbations = np.zeros(len(self.params)) + np.inf\n",
        "        self.kf = KalmanFilterRoutine(self.params, self.kalman_init)\n",
        "        \n",
        "    \n",
        "    def reset(self):\n",
        "        self.kf = KalmanFilterRoutine(self.params, self.kalman_init)\n",
        "    \n",
        "    def zero_buffer(self):\n",
        "        self.buffer_starts = deque(maxlen=self.previous_frames_to_keep)\n",
        "        self.buffer_ends = deque(maxlen=self.previous_frames_to_keep)\n",
        "        \n",
        "    @property\n",
        "    def is_ready(self):\n",
        "        return self.kf.is_ready\n",
        "    \n",
        "    def update(self, **params):\n",
        "        self.prev_params = np.array([params[k] for k in self.params])\n",
        "        if not self.use_kalman:\n",
        "            return\n",
        "        self.kf.update(**params)\n",
        "\n",
        "    \n",
        "    def get_bounds(self):    \n",
        "        if not self.use_kalman or not self.kf.is_ready:\n",
        "            if not self.buffer_starts:\n",
        "                ranges = [self.params_ranges[x] for x in self.params]\n",
        "            else:\n",
        "                ranges = [(start,end) for start, end in zip(0.8 * np.mean(self.buffer_starts, axis=0), \n",
        "                                                            1.2 * np.mean(self.buffer_ends, axis=0))]\n",
        "        else:\n",
        "            diff1 = self.kf.updated_params - self.prev_params\n",
        "            diff2 = self.kf.updated_params_der + 0.5 * self.kf.updated_params_sder\n",
        "            \n",
        "            \n",
        "            changes =  np.maximum(np.abs(diff1 + diff2), self.min_perturbations)\n",
        "            \n",
        "            \n",
        "#             perturbations = np.minimum(np.maximum(\n",
        "#                 changes,self.min_perturbations), self.max_perturbations)\n",
        "            perturbations = changes\n",
        "#             starts = self.kf.updated_params - perturbations\n",
        "#             ends = self.kf.updated_params + perturbations\n",
        "            starts = self.prev_params - perturbations\n",
        "            ends = self.prev_params + perturbations\n",
        "            assert np.all(ends - starts > 0), (changes, self.min_perturbations)\n",
        "#             print(stats, ends)\n",
        "#             if self.strictly_positive_params is not None:\n",
        "#                 flag = np.array([x in self.strictly_positive_params for x in self.params])\n",
        "#                 add = np.maximum(0, - starts[flag])\n",
        "#                 starts[flag] += add\n",
        "#                 ends[flag] += add\n",
        "#             if self.obey_original_ranges:\n",
        "\n",
        "#                 flag = np.array([x is not None for x in self.ranges_limits[:, 0]])\n",
        "#                 starts[flag] = np.maximum(self.ranges_limits[flag, 0], starts[flag])\n",
        "#                 ends[flag] = np.minimum(self.ranges_limits[flag, 1], ends[flag])\n",
        "            ranges = [(start, end) for start, end in zip(starts, ends)]\n",
        "            self.buffer_starts.append(starts)\n",
        "            self.buffer_ends.append(ends)\n",
        "                          \n",
        "        return ranges    \n",
        "    \n",
        "def check_duplicates(x, cols=['left','top']):\n",
        "    assert np.all(x.groupby(cols).size() == 1), (x, x.groupby(cols).size())\n",
        "def mapping_df(combs_generator, tracking, df, previous_mapped=None, \n",
        "               available_oris=(0,1), ignore_starting_preproc=False,\n",
        "               force_local_minimize=True, check_mapping=False, ratio = 0.8):\n",
        "    gameKey,playID,view,frame = df.video_frame.iloc[0].split('_')\n",
        "    gameKey = int(gameKey)\n",
        "    playID = int(playID)\n",
        "    frame = int(frame)\n",
        "    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)]\n",
        "    this_tracking = find_nearest(this_tracking, frame)\n",
        "    df = df.reset_index(drop=True)\n",
        "    \n",
        "    max_p = MAX_COORDS\n",
        "    if view == 'Endzone':\n",
        "        max_cost_thres = MAX_COST_ENDZONE\n",
        "    else:\n",
        "        max_cost_thres = MAX_COST_SIDELINE\n",
        "    same_sgns = 0 # the projected axes on the image need to be reflected as of x or as of y\n",
        "    if view == 'Endzone':\n",
        "        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n",
        "        max_p = max_p[::-1]\n",
        "        # the projected axes need to be reflected both as of x and as of y or stay as is\n",
        "        same_sgns = 1 \n",
        "    if 'conf' in df.columns:\n",
        "        df = df[df['conf']>CONF_THRE].copy()\n",
        "    df_num = len(df)\n",
        "    if not ignore_starting_preproc and (view == 'Sideline') and not combs_generator.is_ready:\n",
        "        inc_mask = (df['top'] >= SIDELINE_START_THRES) & (df['top'] < 720 - SIDELINE_START_THRES)\n",
        "        if not np.all(inc_mask):\n",
        "            print(f\"Removing {(~inc_mask).sum()} bounding boxes that reside in the top or bottom edge of the screen\")\n",
        "            df = df[inc_mask].copy()\n",
        "        \n",
        "    im_centers = df[['left', 'top']].values+ (df[['width', 'height']]/2).values\n",
        "    rl_centers = this_tracking[['x','y']].values\n",
        "    \n",
        "    im_centers = im_centers\n",
        "    \n",
        "    opt_params = None\n",
        "    costs = {0: [], 1: []}\n",
        "    min_cost = 1e7\n",
        "    opt_params = None\n",
        "    for change_ori in available_oris:\n",
        "        # assume 1 yard average height \n",
        "        expanded = np.hstack([rl_centers,\n",
        "                              1 + np.zeros((len(rl_centers),1))])\n",
        "        if same_sgns:\n",
        "            c_translation = np.zeros(2)\n",
        "            c_scaling = np.ones(2)\n",
        "            if change_ori:\n",
        "                c_translation = max_p\n",
        "                c_scaling = - np.ones(2)\n",
        "        else:\n",
        "            if change_ori:\n",
        "                c_translation = np.array([0, max_p[1]])\n",
        "                c_scaling = np.array([1, -1])\n",
        "            else:\n",
        "                c_translation = np.array([max_p[0], 0])\n",
        "                c_scaling = np.array([-1, 1])\n",
        "        expanded[:, :2] = c_scaling * expanded[:, :2] + c_translation\n",
        "        expanded[:, 1] = max_p[1] - expanded[:, 1]\n",
        "\n",
        "\n",
        "        to_opt = combs_generator.params\n",
        "        x0 = [np.mean(combs_generator.params_ranges[x]) for x in to_opt]\n",
        "        bounds = combs_generator.get_bounds()\n",
        "        min_func = lambda p: cost_function(\n",
        "            this_tracking=this_tracking,\n",
        "            expanded=expanded,\n",
        "            im_centers=im_centers,\n",
        "            camera_length=p[to_opt.index('camera_length')],\n",
        "            camera_height=p[to_opt.index('camera_height')],\n",
        "            max_p=max_p,\n",
        "            zdig=p[to_opt.index('zdig')],                                 \n",
        "            xdig=p[to_opt.index('xdig')],\n",
        "            scaling=p[to_opt.index('scaling')],\n",
        "            ret_cost_only=True,\n",
        "            previous_tracking=previous_mapped,\n",
        "            max_cost_thres=None)\n",
        "        \n",
        "        if force_local_minimize or combs_generator.is_ready:\n",
        "            ret = minimize(min_func, x0=x0,\n",
        "                bounds=bounds)\n",
        "#             if ret.fun > max_cost_thres * ratio:\n",
        "#                 print(f'Resetting due to high cost({ret.fun} > {max_cost_thres * ratio})')\n",
        "#                 combs_generator.reset()\n",
        "#                 bounds = combs_generator.get_bounds()\n",
        "        if not combs_generator.is_ready and not force_local_minimize:\n",
        "            ret = basinhopping(min_func,\n",
        "                               x0=x0,niter=100 if combs_generator.buffer_starts else 6000,\n",
        "                               niter_success=5 if combs_generator.buffer_starts else 150,\n",
        "                minimizer_kwargs=dict(bounds=bounds), seed=RANDOM_STATE)\n",
        "            if ret.fun > max_cost_thres * ratio:\n",
        "                print('Basin Hopping Unsuccessful! Resetting due to high cost('\n",
        "                      f'{ret.fun} > {max_cost_thres * ratio})')\n",
        "                combs_generator.reset()\n",
        "                    \n",
        "        cost = ret.fun\n",
        "        if cost < min_cost:\n",
        "            xdig = ret.x[to_opt.index('xdig')]\n",
        "            zdig = ret.x[to_opt.index('zdig')]\n",
        "            scaling = ret.x[to_opt.index('scaling')]\n",
        "            camera_height = ret.x[to_opt.index('camera_height')]\n",
        "            camera_length = ret.x[to_opt.index('camera_length')]\n",
        "            found_params, found_tracking, unmatched_tracking = cost_function(\n",
        "                this_tracking=this_tracking,\n",
        "                expanded=expanded, \n",
        "                im_centers=im_centers,\n",
        "                camera_height=camera_height,\n",
        "                camera_length=camera_length,\n",
        "                max_p=max_p,\n",
        "                zdig=zdig,\n",
        "                xdig=xdig,\n",
        "                scaling=scaling,\n",
        "                ret_cost_only=False, \n",
        "                previous_tracking=previous_mapped,\n",
        "                max_cost_thres=max_cost_thres)\n",
        "            min_cost = cost\n",
        "            opt_ret = ret\n",
        "            opt_params = found_params\n",
        "            opt_params['change_ori'] = change_ori\n",
        "            opt_tracking = found_tracking\n",
        "            opt_unmatched = unmatched_tracking\n",
        "    \n",
        "\n",
        "    if opt_params is None:\n",
        "        combs_generator.reset()\n",
        "        if debug:\n",
        "            print('Failure')\n",
        "            print(ret)\n",
        "        raise\n",
        "    match_to = opt_params['match_to']\n",
        "    match_from = opt_params['match_from']\n",
        "    match_costs = opt_params['match_costs']\n",
        "    df['view'] = view\n",
        "    df[['im_x_remapped', 'im_y_remapped']] = im_centers\n",
        "    df_cols = [col for col in df.columns if col not in ['x','y','x2im', 'y2im', 'player']]\n",
        "    to_double_match = opt_unmatched.copy()\n",
        "    to_double_match_flag = ((to_double_match['x2im'] < 1280) &\n",
        "                       (to_double_match['x2im'] >= 0) &\n",
        "                       (to_double_match['y2im'] < 720) &\n",
        "                       (to_double_match['y2im'] >= 0))\n",
        "    # deactivating it\n",
        "    to_double_match_flag = np.zeros_like(to_double_match_flag)\n",
        "    double_match_aug = None\n",
        "    unmatched_df_inds = list(set(range(len(df))) - set(match_to))\n",
        "    if to_double_match_flag.any():\n",
        "        to_double_match = to_double_match[to_double_match_flag].copy()\n",
        "        dd = distance_matrix(im_centers, to_double_match[['x2im', 'y2im']].values)\n",
        "        dmatch_to, dmatch_from  = linear_sum_assignment(dd)\n",
        "        dcosts = dd[dmatch_to, dmatch_from]\n",
        "        dflag = dcosts <= max_cost_thres\n",
        "        dmatch_to = dmatch_to[dflag]\n",
        "        dmatch_from = dmatch_from[dflag]\n",
        "        \n",
        "#         unmatched_df_inds = list(set(unmatched_df_inds) - set(dmatch_to))\n",
        "        double_match_aug = df[df_cols].iloc[dmatch_to].copy().reset_index(drop=True)\n",
        "        double_match_aug['left'] += 1\n",
        "        double_match_aug[['x','y','x2im', 'y2im', 'player']] = to_double_match.iloc[dmatch_from][\n",
        "            ['x','y','x2im', 'y2im', 'player']].values\n",
        "        double_match_aug['cost'] = dd[dmatch_to, dmatch_from]\n",
        "        opt_unmatched = pd.concat(\n",
        "            [opt_unmatched[~to_double_match_flag],\n",
        "             to_double_match.iloc[list(set(range(len(to_double_match))) - set(dmatch_from))]],axis=0)\n",
        "        \n",
        "        \n",
        "    combs_generator.update(zdig=opt_params['zdig'],\n",
        "                           xdig=opt_params['xdig'],\n",
        "                           scaling=opt_params['scaling'],\n",
        "                           camera_height=opt_params['camera_height'],\n",
        "                           camera_length=opt_params['camera_length'])\n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "    ret = pd.concat(\n",
        "        [\n",
        "            df[df_cols].iloc[match_to].reset_index(drop=True),\n",
        "            opt_tracking[['x','y','x2im', 'y2im', 'player']].reset_index(drop=True)\n",
        "        ],\n",
        "        axis=1).set_index(df.iloc[match_to].index)\n",
        "    ret['cost'] = match_costs\n",
        "    \n",
        "    if double_match_aug is not None:\n",
        "        \n",
        "        ret = pd.concat([ret, double_match_aug],axis=0).reset_index(drop=True)\n",
        "        \n",
        "        \n",
        "        opt_tracking = pd.concat(\n",
        "            [opt_tracking, to_double_match.iloc[dmatch_from]],axis=0).reset_index(drop=True)\n",
        "        \n",
        "    \n",
        "    ret = pd.concat([ret, df.iloc[unmatched_df_inds][df_cols]], axis=0).reset_index(drop=True) # null labels for unmatched\n",
        "    assert df.left.isin(ret.left).all(), (sorted(df.left), sorted(ret.left))\n",
        "    ret['cost'] = ret['cost'].fillna(np.inf)\n",
        "    if double_match_aug is not None:\n",
        "        x = set(unmatched_df_inds) | set(match_to) |set(dmatch_to)\n",
        "        assert  len(x) == df_num, (len(df), x, df_num) \n",
        "        df = pd.concat([df, double_match_aug[df_cols]], axis=0).reset_index(drop=True)\n",
        "        assert len(df) >= df_num, (len(df), df_num)\n",
        "        assert df.left.isin(ret.left).all()\n",
        "    \n",
        "    ret.rename(columns={'player':'label'},inplace=True)\n",
        "    \n",
        "    \n",
        "    if previous_mapped is not None:\n",
        "        previous_mapped = previous_mapped[~previous_mapped['label'].isnull()]\n",
        "    if previous_mapped is not None and (len(previous_mapped) > 0) and ('cost' in previous_mapped.columns):\n",
        "        ori_len = len(ret)\n",
        "        \n",
        "        compared_ret, to_reassign_labels = compare_and_assign(ret, previous_mapped)\n",
        "        if ~to_reassign_labels.empty:\n",
        "            max_permitted_costs = compared_ret['cost'].max()\n",
        "            tracking_to_check = pd.concat([opt_tracking, opt_unmatched],axis=0)\n",
        "            tracking_mask = ~tracking_to_check.player.isin(\n",
        "                compared_ret['label'].values)\n",
        "            to_reassign_flag = ret['label'].isin(to_reassign_labels)\n",
        "            reduced_df = df.merge(ret.loc[to_reassign_flag, ['left', 'top']],\n",
        "                                  on=['left', 'top'], how='inner')\n",
        "            reduced_dist = distance_matrix(reduced_df[['im_x_remapped',\n",
        "                                                       'im_y_remapped']],\n",
        "                                           tracking_to_check[['x2im', 'y2im']])[:, tracking_mask]\n",
        "            reduced_dist[np.isinf(reduced_dist)] = 1e7\n",
        "            try:\n",
        "                matched_to, matched_from = linear_sum_assignment(reduced_dist)\n",
        "            except:\n",
        "                return ret, opt_tracking, opt_params, opt_unmatched\n",
        "            matched_costs = reduced_dist[matched_to, matched_from]\n",
        "            reassigned_ret = pd.concat(\n",
        "                [reduced_df[df_cols].iloc[\n",
        "                    matched_to].reset_index(drop=True),\n",
        "                 tracking_to_check[tracking_mask].iloc[matched_from][\n",
        "                     ['x','y','x2im', 'y2im', 'player']].reset_index(drop=True)],\n",
        "                axis=1).set_index(reduced_df.iloc[matched_to].index)\n",
        "            reassigned_ret['cost'] = matched_costs\n",
        "            reassigned_ret.rename(columns={'player':'label'},inplace=True)\n",
        "            reassigned_ret.loc[reassigned_ret['cost'] > max_permitted_costs, 'label'] = np.nan\n",
        "            \n",
        "            ret = pd.concat([compared_ret, reassigned_ret],axis=0)\n",
        "            mask = ~ret['label'].isnull()\n",
        "        else:\n",
        "            ret = compared_ret\n",
        "    ret = ret.sort_values('left')\n",
        "#     assert df['left'].isin(ret['left']).all(), (df['left'], ret['left'])\n",
        "    return ret[df_cols + ['label', 'cost', 'x2im', 'y2im']], opt_tracking, opt_params, opt_unmatched\n",
        "    \n",
        "def compare_and_assign(ret, previous_mapped):\n",
        "    hist_dist_mat = distance_matrix(\n",
        "    ret[['left', 'top']].values,\n",
        "    previous_mapped[['left', 'top']].values)\n",
        "\n",
        "    matched_to, matched_from = linear_sum_assignment(hist_dist_mat)\n",
        "    costs = np.array([ret.iloc[matched_to]['cost'].values,\n",
        "               previous_mapped.iloc[matched_from]['cost'].values])\n",
        "    to_select = np.argmin(costs,axis=0)\n",
        "    to_keep_previous = to_select == 1\n",
        "    \n",
        "    matched_to_flag = np.zeros(len(ret)).astype(bool)\n",
        "\n",
        "    matched_from = matched_from[to_keep_previous]\n",
        "    matched_to = matched_to[to_keep_previous]\n",
        "    matched_to_flag[matched_to] = True\n",
        "    labels_to_keep_previous = previous_mapped.iloc[matched_from].label\n",
        "    to_change_df = ret[matched_to_flag] .copy()\n",
        "    to_change_df['cost'] = (\n",
        "        to_change_df['cost'].values +\n",
        "        previous_mapped.iloc[matched_from]['cost'].values) / 2\n",
        "    to_change_df['label'] = previous_mapped.iloc[matched_from]['label'].values\n",
        "    to_keep_df = ret[~matched_to_flag].copy()\n",
        "    to_reassign_flag = to_keep_df['label'].isin(to_change_df['label'].values).values\n",
        "    ret = pd.concat([to_change_df, to_keep_df[~to_reassign_flag]],axis=0)\n",
        "    mask = ~ret['label'].isnull()\n",
        "    if len(ret[mask]) != len(ret[mask].drop_duplicates('label')):\n",
        "        display(to_change_df)\n",
        "        display(to_keep_df[~to_reassign_flag])\n",
        "        print(matched_to)\n",
        "        raise\n",
        "   \n",
        "    return ret, to_keep_df['label'][to_reassign_flag]\n",
        "class Mapping:\n",
        "    def __init__(self, tracking, view, use_kalman=True, use_previous=True, available_oris=(0,1),\n",
        "                 init_frames=19, ignore_starting_preproc=False):\n",
        "        self.tracking = tracking\n",
        "        self.use_kalman = use_kalman\n",
        "        self.use_previous = use_previous\n",
        "        self.available_oris = available_oris\n",
        "        self.init_frames = init_frames\n",
        "        self.ignore_starting_preproc = ignore_starting_preproc\n",
        "        \n",
        "        self.buffer_max_cost = deque(maxlen=30)\n",
        "        self.buffer_ori = []\n",
        "        self.buffer_costs = []\n",
        "        dig_step = np.deg2rad(DIG_STEP)\n",
        "        dig_max = np.deg2rad(DIG_MAX)\n",
        "        step_size = int(2 * DIG_MAX / DIG_STEP)\n",
        "        length = MAX_COORDS[0] if view=='Sideline' else MAX_COORDS[1]\n",
        "        self.params_ranges = dict(zdig=[- pi / 3, pi / 3],\n",
        "                                  xdig=[0, pi/3],\n",
        "                                  camera_height=[15, 50],\n",
        "                                  camera_length=[0.3 * length, 0.7 * length],\n",
        "                                  scaling=[20, 80])\n",
        "        self.min_perturbations = dict(zdig=np.deg2rad(5), xdig=np.deg2rad(5), scaling=0.1, camera_length=0.1,\n",
        "                                      camera_height=0.1)\n",
        "        self.max_perturbations = dict(zdig=np.deg2rad(10), xdig=np.deg2rad(10), scaling=1, camera_length=0.2,\n",
        "                                      camera_height=0.2)\n",
        "        \n",
        "        self.combinations_generator = ParamsCombinationsGenerator(\n",
        "            self.params_ranges, strictly_positive_params='scaling', min_perturbations=self.min_perturbations,\n",
        "        max_perturbations=self.max_perturbations, use_kalman=use_kalman, kalman_init=1, obey_original_ranges=False)\n",
        "        self.previous_df = None\n",
        "        self.max_cost_thres=None\n",
        "        self.frame = 0\n",
        "    \n",
        "    def __call__(self, this_df):\n",
        "        try:\n",
        "            self.previous_df, this_tracking, opt_params, opt_unmatched = mapping_df(\n",
        "                self.combinations_generator,\n",
        "                self.tracking, this_df, \n",
        "                previous_mapped=(self.previous_df\n",
        "                                 if self.use_previous else None),\n",
        "                available_oris=self.available_oris,\n",
        "                force_local_minimize=len(self.available_oris)==2, # we dont need much of accuracy when detecting orientation\n",
        "                ignore_starting_preproc=self.ignore_starting_preproc,\n",
        "            )\n",
        "            self.previous_df = pd.concat([self.previous_df, opt_unmatched[\n",
        "                    [col for col in opt_unmatched if col in self.previous_df.columns]]],axis=0)\n",
        "            \n",
        "            if len(self.buffer_ori) < self.init_frames:\n",
        "                self.buffer_ori.append(opt_params['change_ori'])\n",
        "                self.buffer_max_cost.append(opt_params['max_cost'])\n",
        "                self.buffer_costs.append(opt_params['cost'])\n",
        "            if len(self.buffer_ori) == self.init_frames:\n",
        "                ori_df = pd.DataFrame({'ori': self.buffer_ori, 'cost': self.buffer_costs})\n",
        "                mean_costs = ori_df.groupby('ori').median()\n",
        "                if len(self.available_oris) == 2:\n",
        "                    self.available_oris = [mean_costs.iloc[np.argmax(mean_costs)]]\n",
        "                self.max_cost_thres = 1.1 * np.max(self.buffer_max_cost)\n",
        "        except KeyboardInterrupt:\n",
        "            raise\n",
        "        except:\n",
        "            if debug:\n",
        "                raise\n",
        "            traceback.print_exc()\n",
        "            self.previous_df, this_tracking, opt_params, opt_unmatched = mapping_df_fallback(self.tracking, this_df)\n",
        "            opt_params['error'] = traceback.format_exc()\n",
        "        return self.previous_df[~self.previous_df.label.isnull()].copy(), this_tracking, opt_params, opt_unmatched\n",
        "\n",
        "\n",
        "def apply_on_video(tracking, video_df):\n",
        "    submission_df_list = []\n",
        "    df_list = list(video_df.groupby('frame'))\n",
        "    view = video_df.iloc[0]['video_frame'].split('_')[2]\n",
        "    ori_mapping = Mapping(tracking, view=view, use_kalman=False, use_previous=False, ignore_starting_preproc=True)\n",
        "    print('Detecting video view orientation...')\n",
        "    for frame in tqdm(np.linspace(1, len(df_list)-1, ori_mapping.init_frames).astype(int)):\n",
        "        _, this_df = df_list[frame]\n",
        "        ori_mapping(this_df)\n",
        "    detected_ori = [mode(ori_mapping.buffer_ori)] if ori_mapping.buffer_ori else [0,1]\n",
        "    print(ori_mapping.buffer_ori)\n",
        "    print('Detected orientation:',detected_ori, '. Mapping...')\n",
        "    \n",
        "    mapping = Mapping(tracking,view=view,\n",
        "                      available_oris=detected_ori)\n",
        "    opt_params_dict = {}\n",
        "    try:\n",
        "        for frame, this_df in tqdm(df_list):\n",
        "            df, _, opt_params, _ = mapping(this_df)\n",
        "            if debug:\n",
        "                opt_params_dict[frame] = opt_params\n",
        "            submission_df_list.append(df)\n",
        "        submission_df = pd.concat(submission_df_list)\n",
        "    except KeyboardInterrupt:\n",
        "        if debug:\n",
        "            with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "                display(pd.DataFrame(opt_params_dict).T)\n",
        "        raise\n",
        "    return submission_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o607vLR3W6D_"
      },
      "source": [
        "videos_dfs = list(helmets.groupby('video'))\n",
        "if len(videos_dfs) == 1:\n",
        "    submission_df_list = [apply_on_video(tracking, videos_dfs[0][1])]\n",
        "else:\n",
        "    submission_df_list = Parallel(n_jobs=-1)(delayed(apply_on_video)(tracking, video_df) for _, video_df in tqdm(videos_dfs))\n",
        "submission_df = pd.concat(submission_df_list)\n",
        "submission_df.to_csv('submission-baseline.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfplfbiFW6Au"
      },
      "source": [
        "submission_df[['left','width','top','height']]=submission_df[['left','width','top','height']].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srFVqifLW59y"
      },
      "source": [
        "!pip install ../input/cythonbbox/cython_bbox-0.1.3/ > /dev/null 2>&1\n",
        "!pip install ../input/labpython/lap-0.4.0/ > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DzlIm7vW564"
      },
      "source": [
        "import sys\n",
        "sys.path.append('../input/easydict-master/easydict-master/')\n",
        "# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\n",
        "sys.path.append('../input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\n",
        "from deep_sort.deep_sort import DeepSort\n",
        "from utils.parser import get_config\n",
        "sys.path.append('../input/')\n",
        "from tracker.byte_tracker import BYTETracker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLEYP58MW54B"
      },
      "source": [
        "%%writefile deepsort.yaml\n",
        "\n",
        "DEEPSORT:\n",
        "  REID_CKPT: \"../input/yolov5-deepsort-pytorch/ckpt.t7\"\n",
        "  MAX_DIST: 0.15\n",
        "  MIN_CONFIDENCE: 0.35\n",
        "  NMS_MAX_OVERLAP: 0.6\n",
        "  MAX_IOU_DISTANCE: 0.9\n",
        "  MAX_AGE: 9\n",
        "  N_INIT: 1\n",
        "  NN_BUDGET: 45"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLBvdXfBW51N"
      },
      "source": [
        "def compute_color_for_id(label):\n",
        "    \"\"\"\n",
        "    Simple function that adds fixed color depending on the id\n",
        "    \"\"\"\n",
        "    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
        "\n",
        "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
        "    return tuple(color)\n",
        "\n",
        "def plot_one_box(x, im, color=None, label=None, line_thickness=3):\n",
        "    # Plots one bounding box on image 'im' using OpenCV\n",
        "    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n",
        "    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label: \n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "    return im\n",
        "class ValidRegionTracker:\n",
        "    def __init__(self):\n",
        "        self.state_surface = None\n",
        "        self.boundary_flag = None\n",
        "        self.input_shape = (512,512)\n",
        "        self.mask5 = np.ones((5,5), np.uint8)\n",
        "        self.mask3 = np.ones((3,3), np.uint8)\n",
        "        self.mask15 = np.ones((15,15), np.uint8)\n",
        "        self.large_mask = np.ones((self.input_shape[1]//5,self.input_shape[0]//5), np.uint8)\n",
        "        \n",
        "    def detect(self, image_data):\n",
        "        og_shape = image_data.shape[:2][::-1]\n",
        "        mask = self.get_mask(cv2.resize(image_data, self.input_shape))\n",
        "        return cv2.resize(\n",
        "                    mask.astype(np.uint8), og_shape, 0, 0, cv2.INTER_NEAREST) > 0\n",
        "\n",
        "    def get_mask(self, image_data):\n",
        "\n",
        "        \n",
        "        hls_img = cv2.cvtColor(image_data,  cv2.COLOR_RGB2HLS)\n",
        "        white_obj_mask = cv2.threshold(hls_img[:,:,1],150,1, cv2.THRESH_BINARY)[1]\n",
        "        seeds = cv2.erode(\n",
        "            cv2.morphologyEx(white_obj_mask.astype(np.uint8), cv2.MORPH_OPEN, self.mask5),\n",
        "            self.mask3)\n",
        "        seeds[3:-3,3:-3] = 0\n",
        "        sure_fg = seeds\n",
        "        unknown = cv2.subtract(cv2.threshold(hls_img[:,:,1],100,1,cv2.THRESH_BINARY)[1],sure_fg)\n",
        "        _, markers = cv2.connectedComponents(sure_fg)\n",
        "        markers = markers+1\n",
        "        markers[unknown==1] = 0\n",
        "        img = cv2.cvtColor(white_obj_mask * 255, cv2.COLOR_GRAY2RGB)\n",
        "        cv2.watershed(img, markers)\n",
        "        white_obj_on_im_edges = (markers>1).astype(np.uint8)\n",
        "        white_obj_on_im_edges = cv2.morphologyEx(white_obj_on_im_edges, cv2.MORPH_CLOSE,self.mask15)\n",
        "        white_obj_on_im_edges = cv2.morphologyEx(white_obj_on_im_edges, cv2.MORPH_OPEN, self.mask15)\n",
        "        from math import pi, sqrt\n",
        "        boundary_flag = np.zeros(white_obj_on_im_edges.shape[:2])\n",
        "        if self.boundary_flag is not None:\n",
        "            boundary_flag = cv2.erode(self.boundary_flag, self.mask15)\n",
        "        to_detect_edges = white_obj_on_im_edges\n",
        "        edges = cv2.morphologyEx(\n",
        "                cv2.Canny(to_detect_edges * 255,0,1,apertureSize = 3),cv2.MORPH_CLOSE,\n",
        "                self.mask15)\n",
        "        lines = cv2.HoughLinesP(\n",
        "            edges,\n",
        "            1, pi/180,100,maxLineGap=3\n",
        "            )\n",
        "        if lines is not None:\n",
        "            # keep 4 largest\n",
        "            lines_lengths = [ sqrt((x2-x1)**2 + (y2-y1)**2) for (x1,y1,x2,y2) in [l[0] for l in lines]]\n",
        "            lines = lines[np.argsort(lines_lengths)[-4:],:,:]\n",
        "            for line in lines:\n",
        "                x1,y1,x2,y2 = line[0]\n",
        "                cv2.line(boundary_flag,(x1,y1),(x2,y2),1,2)\n",
        "        sure_fg = boundary_flag.astype(np.uint8)\n",
        "        unknown = cv2.subtract(white_obj_on_im_edges,sure_fg)\n",
        "        _, markers = cv2.connectedComponents(sure_fg)\n",
        "        markers = markers+1\n",
        "        markers[unknown==1] = 0\n",
        "        img = cv2.cvtColor(\n",
        "            white_obj_on_im_edges*255, cv2.COLOR_GRAY2RGB)\n",
        "        cv2.watershed(\n",
        "            img, markers)\n",
        "        markers = (markers > 1).astype(np.uint8)\n",
        "        self.boundary_flag = cv2.morphologyEx(\n",
        "            markers, cv2.MORPH_CLOSE, self.large_mask)\n",
        "\n",
        "        return self.boundary_flag == 0\n",
        "def deepsort_helmets(video_data,\n",
        "                     video_dir,\n",
        "                     deepsort_config='deepsort.yaml',\n",
        "                     plot=False,\n",
        "                     plot_frames=[]):\n",
        "    \n",
        "    # Setup Deepsort\n",
        "    cfg = get_config()\n",
        "    cfg.merge_from_file(deepsort_config)    \n",
        "    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n",
        "                        max_dist=cfg.DEEPSORT.MAX_DIST,\n",
        "                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n",
        "                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n",
        "                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n",
        "                        max_age=cfg.DEEPSORT.MAX_AGE,\n",
        "                        n_init=cfg.DEEPSORT.N_INIT,\n",
        "                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n",
        "                        use_cuda=True)\n",
        "    tracker = ValidRegionTracker()\n",
        "    # Run through frames.\n",
        "    video_data = video_data.sort_values('frame').reset_index(drop=True)\n",
        "    ds = []\n",
        "    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n",
        "        d['x'] = (d['left'] + round(d['width'] / 2))\n",
        "        d['y'] = (d['top'] + round(d['height'] / 2))\n",
        "\n",
        "        xywhs = d[['x','y','width','height']].values\n",
        "\n",
        "        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}.mp4')\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n",
        "        success, image = cap.read()\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = tracker.detect(image)\n",
        "        image = image * mask[:, :, np.newaxis]\n",
        "        confs = np.ones([len(d),])\n",
        "        clss =  np.zeros([len(d),])\n",
        "        outputs = deepsort.update(xywhs, confs, clss, image)\n",
        "\n",
        "        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n",
        "            for j, (output, conf) in enumerate(zip(outputs, confs)): \n",
        "\n",
        "                bboxes = output[0:4]\n",
        "                id = output[4]\n",
        "                cls = output[5]\n",
        "\n",
        "                c = int(cls)  # integer class\n",
        "                label = f'{id}'\n",
        "                color = compute_color_for_id(id)\n",
        "                im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n",
        "            fig, ax = plt.subplots(figsize=(15, 10))\n",
        "            video_frame = d['video_frame'].values[0]\n",
        "            ax.set_title(f'Deepsort labels: {video_frame}')\n",
        "            plt.imshow(im)\n",
        "            plt.show()\n",
        "\n",
        "        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n",
        "        if len(preds_df) > 0:\n",
        "            # TODO Fix this messy merge\n",
        "            d[['left','top']] = d[['left','top']].astype(int)\n",
        "            preds_df[['left','top']] = preds_df[['left','top']].astype(int)\n",
        "            d = pd.merge_asof(d.sort_values(['left','top']),\n",
        "                              preds_df[['left','top','deepsort_cluster']] \\\n",
        "                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n",
        "                              direction='nearest')\n",
        "        ds.append(d)\n",
        "    dout = pd.concat(ds)\n",
        "    return dout\n",
        "\n",
        "def add_deepsort_label_col(out):\n",
        "    # Find the top occuring label for each deepsort_cluster\n",
        "    cum = out[~out['label'].isnull()].groupby('deepsort_cluster')['label'].value_counts() \\\n",
        "        .sort_values(ascending=False).to_frame() \\\n",
        "        .rename(columns={'label':'label_count'}) \\\n",
        "        .reset_index() \\\n",
        "        .groupby(['deepsort_cluster']) \\\n",
        "        .first()\n",
        "    \n",
        "    sortlabel_map = cum['label'].to_dict()\n",
        "    # Find the # of times that label appears for the deepsort_cluster.\n",
        "    sortlabelcount_map = cum['label_count'].to_dict()\n",
        "    \n",
        "    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n",
        "    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n",
        "    return out\n",
        "\n",
        "def score_vs_deepsort(myvideo, out, labels):\n",
        "    # Score the base predictions compared to the deepsort postprocessed predictions.\n",
        "    myvideo_mp4 = myvideo + '.mp4'\n",
        "    labels_video = labels.query('video == @myvideo_mp4')\n",
        "    scorer = NFLAssignmentScorer(labels_video)\n",
        "    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n",
        "    base_video_score = scorer.score(out_deduped)\n",
        "    \n",
        "    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n",
        "    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n",
        "    deepsort_video_score = scorer.score(out_preds)\n",
        "    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')\n",
        "submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_')\n",
        "submission_df['frame'] = submission_df['video_frame'].str.split('_').str[-1].astype('int')\n",
        "\n",
        "if debug:\n",
        "    video_dir = '../input/nfl-health-and-safety-helmet-assignment/train/'\n",
        "else:\n",
        "    video_dir = '../input/nfl-health-and-safety-helmet-assignment/test/'\n",
        "\n",
        "# Loop through test videos and apply. If in debug mode show the score change.\n",
        "out_ds = []\n",
        "outs = []\n",
        "for myvideo, video_data in tqdm(submission_df.groupby('video'), total=submission_df['video'].nunique()):\n",
        "    print(f'==== {myvideo} ====')\n",
        "    if debug:\n",
        "        # Plot deepsort labels when in debug mode.\n",
        "        out = deepsort_helmets(video_data, video_dir, plot_frames=[10, 150, 250])\n",
        "    else:\n",
        "        out = deepsort_helmets(video_data, video_dir)\n",
        "    out_ds.append(out)\n",
        "    out = add_deepsort_label_col(out)\n",
        "    outs.append(out)\n",
        "    if debug:\n",
        "        # Score\n",
        "        score_vs_deepsort(myvideo, out, labels)\n",
        "submission_deepsort = pd.concat(outs).copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHPXrioxW5yW"
      },
      "source": [
        "ss = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n",
        "# Final Checks\n",
        "submission_deepsort.reset_index(inplace=True, drop=True)\n",
        "submission_deepsort['label_deepsort'] = submission_deepsort['label_deepsort'].fillna(submission_deepsort['label'])\n",
        "submission_deepsort = submission_deepsort[~submission_deepsort['label_deepsort'].isnull()]\n",
        "submission_deepsort = submission_deepsort.drop('label', axis=1) \\\n",
        "    .rename(columns={'label_deepsort':'label'})[ss.columns]\n",
        "# Drop duplicate labels\n",
        "submission_deepsort = submission_deepsort.loc[\n",
        "    ~submission_deepsort[['video_frame','label']].duplicated()]\n",
        "check_submission(submission_deepsort)\n",
        "submission_deepsort[['left','width','top','height']] = submission_deepsort[['left','width','top','height']].astype(int)\n",
        "submission_deepsort = submission_deepsort.dropna(axis=0)\n",
        "submission_deepsort.to_csv('submission.csv', index=False)\n",
        "if debug:\n",
        "    submission_deepsort['video'] = submission_deepsort['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n",
        "    debug_videos = submission_deepsort['video'].unique()\n",
        "    debug_labels = labels.query('video in @debug_videos')\n",
        "    scorer = NFLAssignmentScorer(debug_labels)\n",
        "    scorer.score(submission_deepsort)\n",
        "    for video in debug_videos:\n",
        "        # Create video showing predictions for one of the videos.\n",
        "        video_out = video_with_predictions(\n",
        "            f'../input/nfl-health-and-safety-helmet-assignment/train/{video}',\n",
        "            scorer.sub_labels.fillna(0))\n",
        "\n",
        "        frac = 0.60 # scaling factor for display\n",
        "        display(Video(data=video_out,\n",
        "                      embed=True,\n",
        "                      height=int(720*frac),\n",
        "                      width=int(1280*frac))\n",
        "               )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}