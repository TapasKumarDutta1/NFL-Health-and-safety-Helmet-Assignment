{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_roc_auc_with_uid_embedding_swa",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_roc_auc_with_uid_embedding_swa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAeHxBw8EEt"
      },
      "source": [
        "Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstQrkXM8Bz9"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IonOu6819IW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a99de3-a444-4844-b156-110de7e804fa"
      },
      "source": [
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 54.0MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 94% 49.0M/52.2M [00:00<00:00, 58.3MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 59.7MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 219MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 99% 58.0M/58.3M [00:00<00:00, 70.6MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 99.4MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 162MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvhOLFro71iv"
      },
      "source": [
        "loading drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6000da9-94ff-4e81-d79d-f2a15291d44e"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZi5I0Va7-Af"
      },
      "source": [
        "Loading dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "ff1d0f0f-1768-404f-cc70-674d0f0f466a"
      },
      "source": [
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train_id.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test_id.csv',index_col=[0])\n",
        "trn.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>C9_std_isna</th>\n",
              "      <th>C10_std_isna</th>\n",
              "      <th>C11_std_isna</th>\n",
              "      <th>C12_std_isna</th>\n",
              "      <th>C13_std_isna</th>\n",
              "      <th>C14_std_isna</th>\n",
              "      <th>D1_mean_isna</th>\n",
              "      <th>D1_std_isna</th>\n",
              "      <th>D2_mean_isna</th>\n",
              "      <th>D2_std_isna</th>\n",
              "      <th>D3_mean_isna</th>\n",
              "      <th>D3_std_isna</th>\n",
              "      <th>D4_mean_isna</th>\n",
              "      <th>D4_std_isna</th>\n",
              "      <th>D5_mean_isna</th>\n",
              "      <th>D5_std_isna</th>\n",
              "      <th>D6_mean_isna</th>\n",
              "      <th>D6_std_isna</th>\n",
              "      <th>D7_mean_isna</th>\n",
              "      <th>D7_std_isna</th>\n",
              "      <th>D8_mean_isna</th>\n",
              "      <th>D8_std_isna</th>\n",
              "      <th>D9_mean_isna</th>\n",
              "      <th>D9_std_isna</th>\n",
              "      <th>D10_mean_isna</th>\n",
              "      <th>D10_std_isna</th>\n",
              "      <th>D11_mean_isna</th>\n",
              "      <th>D11_std_isna</th>\n",
              "      <th>D12_mean_isna</th>\n",
              "      <th>D12_std_isna</th>\n",
              "      <th>D13_mean_isna</th>\n",
              "      <th>D13_std_isna</th>\n",
              "      <th>D14_mean_isna</th>\n",
              "      <th>D14_std_isna</th>\n",
              "      <th>D15_mean_isna</th>\n",
              "      <th>D15_std_isna</th>\n",
              "      <th>V1_mean_isna</th>\n",
              "      <th>V1_std_isna</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wnan315.013926-13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wgmail.com325.027551.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Woutlook.com330.046631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wyahoo.com476.018132-111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hgmail.com420.044971.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 619 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2  ...  V1_std_isna  isFraud                          id\n",
              "0  1.0  0.0  0.0  ...            1        0         Wnan315.013926-13.0\n",
              "1  1.0  0.0  0.0  ...            1        0      Wgmail.com325.027551.0\n",
              "2  1.0  0.0  0.0  ...            0        0    Woutlook.com330.046631.0\n",
              "3  1.0  0.0  0.0  ...            1        0  Wyahoo.com476.018132-111.0\n",
              "4  0.0  0.0  0.0  ...            1        0      Hgmail.com420.044971.0\n",
              "\n",
              "[5 rows x 619 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEIUFVW8iAC"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4af11c0-9eaf-4df8-ef67-a1ef93b14ce5"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2793.39 MB\n",
            "Memory usage after optimization is: 678.37 MB\n",
            "Decreased by 75.7%\n",
            "Memory usage of dataframe is 2392.90 MB\n",
            "Memory usage after optimization is: 580.09 MB\n",
            "Decreased by 75.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjn9ePhArDJ"
      },
      "source": [
        "trn=trn.replace([np.inf,-np.inf],np.nan)\n",
        "tst=tst.replace([np.inf,-np.inf],np.nan)\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRqrD6vz8ol6"
      },
      "source": [
        "Making the callbacks and loading model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW"
      },
      "source": [
        "dk={}\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data,epochs):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "        self.epochs=epochs\n",
        "        self.val=0\n",
        "        self.wts=[]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        if roc_val>self.val:\n",
        "          self.val=roc_val\n",
        "          self.epoch=10\n",
        "          self.wts=self.model.get_weights()\n",
        "        else:\n",
        "          self.epoch-=1\n",
        "        if self.epoch==0:\n",
        "          self.model.set_weights(self.wts)\n",
        "          self.model.stop_training = True\n",
        "        print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model(dim):\n",
        "  K.clear_session()\n",
        "\n",
        "\n",
        "  uid=Input((1,))\n",
        "  inp=Input((873,))\n",
        "  emb=Embedding(input_dim=dim,output_dim=4)(uid)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Concatenate()([emb,x])\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=[inp,uid],outputs=x)\n",
        "  return mod\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZH6xEokzPfj"
      },
      "source": [
        "Adding all datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZw0LXIzPG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64335bb-251f-4866-bab7-b566bf2a22c8"
      },
      "source": [
        "trn_s=trn.shape[0]\n",
        "df=pd.concat([trn,tst],0).reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "autoenc=pd.read_csv('/content/gdrive/My Drive/fraud/without_id.csv',index_col=[0])\n",
        "\n",
        "autoenc.columns=[i for i in range(444,444+autoenc.shape[1])]\n",
        "\n",
        "\n",
        "df=pd.concat([df,autoenc],1)\n",
        "df=reduce_mem_usage(df)\n",
        "del([autoenc])\n",
        "gc.collect()\n",
        "\n",
        "trn=df.loc[:trn_s-1]\n",
        "tst=df.loc[trn_s:].reset_index(drop=True)\n",
        "del([df])\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 3384.06 MB\n",
            "Memory usage after optimization is: 1783.79 MB\n",
            "Decreased by 47.3%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxmq8JSOz6Hk"
      },
      "source": [
        "categorical=[str(i) for i in range(444)]\n",
        "trn[categorical]=trn[categorical].astype('uint8')\n",
        "tst[categorical]=tst[categorical].astype('uint8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVXGvLePKR8T"
      },
      "source": [
        "def rac(y_true, y_pred):\n",
        "    \"\"\" ROC AUC Score.\n",
        "    Approximates the Area Under Curve score, using approximation based on\n",
        "    the Wilcoxon-Mann-Whitney U statistic.\n",
        "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
        "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
        "    Measures overall performance for a full range of threshold levels.\n",
        "    Arguments:\n",
        "        y_pred: `Tensor`. Predicted values.\n",
        "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(\"RocAucScore\"):\n",
        "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
        "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
        "        pos = tf.expand_dims(pos, 0)\n",
        "        neg = tf.expand_dims(neg, 1)\n",
        "        # original paper suggests performance is robust to exact parameter choice\n",
        "        gamma = 0.3\n",
        "        p     = 1.5\n",
        "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
        "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
        "        return tf.reduce_sum(tf.pow(-masked, p))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w55g3o_D_eYn"
      },
      "source": [
        "class stocasticensembling(Callback):\r\n",
        "  def __init__(self,model_name,alpha1,alpha2,iter_per_epoch,cycle_len,seqs_dict,start_inx=0,save_se_weights=False,folder='/content',**kwargs):\r\n",
        "    #save_se_weights: save after each epoch ?\r\n",
        "\r\n",
        "    super(stocasticensembling,self).__init__()\r\n",
        "    self.model_count=0\r\n",
        "    self.alpha1=alpha1\r\n",
        "    self.alpha2=alpha2\r\n",
        "    self.clr_iterations=0\r\n",
        "    self.cycle_num=cycle_len\r\n",
        "    self.cycle_len=cycle_len\r\n",
        "    self.iter_per_epoch=iter_per_epoch\r\n",
        "    self.iter_per_cycle = self.cycle_len * self.iter_per_epoch\r\n",
        "    self.save_se_weights=save_se_weights\r\n",
        "    self.start_inx=start_inx\r\n",
        "    self.swa_weights=[]\r\n",
        "    self.folder=folder\r\n",
        "    self.seqs_dict=seqs_dict\r\n",
        "    self.model_name=model_name\r\n",
        "    self.prob_dict={k: [] for k in self.seqs_dict.keys()}\r\n",
        "    self.lrs=[]\r\n",
        "\r\n",
        "  def on_train_end(self,logs={}):\r\n",
        "    self.weight_update()\r\n",
        "    self.model.set_weights(self.swa_weights)\r\n",
        "    self.snapsort()\r\n",
        "    for seq_names,probs in self.prob_dict.items():\r\n",
        "      self.prob_dict[seq_names]=np.concatenate(probs,axis=-1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_begin(self,epoch,logs=None):\r\n",
        "    self.current_epoch=epoch\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_end(self,epoch,logs=None):\r\n",
        "    self.cycle_num+=1\r\n",
        "    if self._t_cycle() !=1:\r\n",
        "      return\r\n",
        "    self.snapsort()\r\n",
        "    self.weight_update()\r\n",
        "    self.model_count+=1\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_batch_begin(self,batch,logs=None):\r\n",
        "    self.clr_iterations+=1\r\n",
        "    lr=self._clr_schedule()\r\n",
        "    self.lrs.append(lr)\r\n",
        "    K.set_value(self.model.optimizer.lr,lr)\r\n",
        "  \r\n",
        "  \r\n",
        "  def snapsort(self):\r\n",
        "    for seq_name,seq in self.seqs_dict.items():\r\n",
        "      self.prob_dict[seq_name].append(self.model.predict(seq,steps=len(seq)))\r\n",
        "  \r\n",
        "  \r\n",
        "  def weight_update(self):\r\n",
        "    weights=self.model.get_weights()\r\n",
        "    if self.model_count==0:\r\n",
        "      self.swa_weights=weights\r\n",
        "    for i in range(0,len(weights)):\r\n",
        "      self.swa_weights[i]=(self.swa_weights[i]*self.model_count+weights[i])/(self.model_count+1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def _t_cycle(self):\r\n",
        "        return (((self.clr_iterations - 1) % self.iter_per_cycle) + 1) / self.iter_per_cycle\r\n",
        "  \r\n",
        "  \r\n",
        "  def _clr_schedule(self):\r\n",
        "    return ((1.0 - 1.0 *self._t_cycle()) * self.alpha2) + (1.0 *self._t_cycle() *self.alpha1)\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oor5OujA6Bz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "7583c572-2df4-4385-f398-5cc7f5658539"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from matplotlib import pyplot as plt\n",
        "splits=KFold(n_splits=5)\n",
        "gc.collect()\n",
        "pre=np.zeros((506691,1))\n",
        "tst=tst.drop(['isFraud'],1)\n",
        "for train_index,test_index in tqdm(splits.split(trn)):\n",
        "  X_train, X_test = trn.loc[train_index], trn.loc[test_index]\n",
        "  y_train, y_test = X_train['isFraud'], X_test['isFraud']\n",
        "  ids={}\n",
        "  for en,id in enumerate(X_train['id'].unique()):\n",
        "    ids[id]=en+2\n",
        "  X_train['id']=X_train['id'].map(lambda x: ids.get(x,1))\n",
        "  X_test['id']=X_test['id'].map(lambda x: ids.get(x,1))\n",
        "  dim=X_train['id'].nunique()+2\n",
        "  gc.collect()\n",
        "  trn_id,tst_id=X_train['id'],X_test['id']\n",
        "  X_train=X_train.drop(['isFraud','id'],1)\n",
        "  X_test=X_test.drop(['isFraud','id'],1)\n",
        "  mod=load_model(dim)\n",
        "  roc = RocCallback(validation_data=([X_test,tst_id], y_test),epochs=10)\n",
        "  mod.compile(optimizer=Nadam(),loss=rac)\n",
        "  es=EarlyStopping(monitor='acu_val',min_delta=0.0001,mode='min',restore_best_weights=True,patience=10)\n",
        "\n",
        "  se = stocasticensembling(seqs_dict=seqs_dict, cycle_len=12, iter_per_epoch=231,\n",
        "                                  alpha1=1e-4, alpha2=1e-3,\n",
        "                                   model_name=\"model\", verbose=1)\n",
        "  hist = mod.fit([X_train,trn_id],y_train,validation_data=([X_test,tst_id],y_test),batch_size=2048,epochs=24,callbacks=[se])\n",
        "  \n",
        "  plt.plot(hist.history['loss'])\n",
        "  plt.savefig('/content/gdrive/My Drive/fraud/roc_approximation_'+str(en)+'.png')\n",
        "  plt.show()\n",
        "\n",
        "  del[(X_train,y_train)]\n",
        "  gc.collect()\n",
        "\n",
        "  mod.fit([X_test,tst_id],y_test,epochs=2,batch_size=2048)\n",
        "  pre+=mod.predict([tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))])/5\n",
        "  \n",
        "  del([X_test,y_test,mod])\n",
        "  gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-18e145f1dbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acu_val'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   se = stocasticensembling(seqs_dict=seqs_dict, cycle_len=12, iter_per_epoch=231,\n\u001b[0m\u001b[1;32m     26\u001b[0m                                   \u001b[0malpha1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                    model_name=\"model\", verbose=1)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seqs_dict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYgkVd5_NVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0fb349dd-79e9-4199-a2d2-8483a1b02aa9"
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv.zip')\n",
        "sub['isFraud']=pre\n",
        "sub=sub.set_index('TransactionID')\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.047033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.056691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.162671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.093753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.070247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.047033\n",
              "3663550        0.056691\n",
              "3663551        0.162671\n",
              "3663552        0.093753\n",
              "3663553        0.070247"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZlw01oHayo"
      },
      "source": [
        "sub.to_csv('sub.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FeqwiR2HcSI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e085e519-0daf-405c-cea8-af9412e52cd0"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d5e72fb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeWMkwJIWng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}