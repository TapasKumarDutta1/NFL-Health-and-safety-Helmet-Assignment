{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_with_uid_embedding_swa.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_with_uid_embedding_swa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAeHxBw8EEt"
      },
      "source": [
        "Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstQrkXM8Bz9"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IonOu6819IW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26efdc0-a7f6-415a-fdf7-0b1a3238b66b"
      },
      "source": [
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvhOLFro71iv"
      },
      "source": [
        "loading drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1611181d-7fe4-4582-ec73-0127ebfdaf54"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZi5I0Va7-Af"
      },
      "source": [
        "Loading dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "15414098-6301-4929-9e1b-68fec0a2dd29"
      },
      "source": [
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train_id.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test_id.csv',index_col=[0])\n",
        "trn.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>C9_std_isna</th>\n",
              "      <th>C10_std_isna</th>\n",
              "      <th>C11_std_isna</th>\n",
              "      <th>C12_std_isna</th>\n",
              "      <th>C13_std_isna</th>\n",
              "      <th>C14_std_isna</th>\n",
              "      <th>D1_mean_isna</th>\n",
              "      <th>D1_std_isna</th>\n",
              "      <th>D2_mean_isna</th>\n",
              "      <th>D2_std_isna</th>\n",
              "      <th>D3_mean_isna</th>\n",
              "      <th>D3_std_isna</th>\n",
              "      <th>D4_mean_isna</th>\n",
              "      <th>D4_std_isna</th>\n",
              "      <th>D5_mean_isna</th>\n",
              "      <th>D5_std_isna</th>\n",
              "      <th>D6_mean_isna</th>\n",
              "      <th>D6_std_isna</th>\n",
              "      <th>D7_mean_isna</th>\n",
              "      <th>D7_std_isna</th>\n",
              "      <th>D8_mean_isna</th>\n",
              "      <th>D8_std_isna</th>\n",
              "      <th>D9_mean_isna</th>\n",
              "      <th>D9_std_isna</th>\n",
              "      <th>D10_mean_isna</th>\n",
              "      <th>D10_std_isna</th>\n",
              "      <th>D11_mean_isna</th>\n",
              "      <th>D11_std_isna</th>\n",
              "      <th>D12_mean_isna</th>\n",
              "      <th>D12_std_isna</th>\n",
              "      <th>D13_mean_isna</th>\n",
              "      <th>D13_std_isna</th>\n",
              "      <th>D14_mean_isna</th>\n",
              "      <th>D14_std_isna</th>\n",
              "      <th>D15_mean_isna</th>\n",
              "      <th>D15_std_isna</th>\n",
              "      <th>V1_mean_isna</th>\n",
              "      <th>V1_std_isna</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wnan315.013926-13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wgmail.com325.027551.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Woutlook.com330.046631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wyahoo.com476.018132-111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hgmail.com420.044971.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 619 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2  ...  V1_std_isna  isFraud                          id\n",
              "0  1.0  0.0  0.0  ...            1        0         Wnan315.013926-13.0\n",
              "1  1.0  0.0  0.0  ...            1        0      Wgmail.com325.027551.0\n",
              "2  1.0  0.0  0.0  ...            0        0    Woutlook.com330.046631.0\n",
              "3  1.0  0.0  0.0  ...            1        0  Wyahoo.com476.018132-111.0\n",
              "4  0.0  0.0  0.0  ...            1        0      Hgmail.com420.044971.0\n",
              "\n",
              "[5 rows x 619 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEIUFVW8iAC"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502ffa80-a71c-463d-cd7d-8c84225392a6"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2793.39 MB\n",
            "Memory usage after optimization is: 678.37 MB\n",
            "Decreased by 75.7%\n",
            "Memory usage of dataframe is 2392.90 MB\n",
            "Memory usage after optimization is: 580.09 MB\n",
            "Decreased by 75.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjn9ePhArDJ"
      },
      "source": [
        "trn=trn.replace([np.inf,-np.inf],np.nan)\n",
        "tst=tst.replace([np.inf,-np.inf],np.nan)\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRqrD6vz8ol6"
      },
      "source": [
        "Making the callbacks and loading model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW"
      },
      "source": [
        "dk={}\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data,epochs):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "        self.epochs=epochs\n",
        "        self.val=0\n",
        "        self.wts=[]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        if roc_val>self.val:\n",
        "          self.val=roc_val\n",
        "          self.epoch=10\n",
        "          self.wts=self.model.get_weights()\n",
        "        else:\n",
        "          self.epoch-=1\n",
        "        if self.epoch==0:\n",
        "          self.model.set_weights(self.wts)\n",
        "          self.model.stop_training = True\n",
        "        print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model(dim):\n",
        "  K.clear_session()\n",
        "\n",
        "\n",
        "  uid=Input((1,))\n",
        "  inp=Input((873,))\n",
        "  emb=Embedding(input_dim=dim,output_dim=4)(uid)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Concatenate()([emb,x])\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=[inp,uid],outputs=x)\n",
        "  return mod\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZH6xEokzPfj"
      },
      "source": [
        "Adding all datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZw0LXIzPG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c4ddd6-7ed6-4640-ee25-5d5d1ed379d2"
      },
      "source": [
        "trn_s=trn.shape[0]\n",
        "df=pd.concat([trn,tst],0).reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "autoenc=pd.read_csv('/content/gdrive/My Drive/fraud/without_id.csv',index_col=[0])\n",
        "autoenc=reduce_mem_usage(autoenc)\n",
        "\n",
        "autoenc.columns=[i for i in range(444,444+autoenc.shape[1])]\n",
        "\n",
        "\n",
        "df=pd.concat([df,autoenc],1)\n",
        "del([autoenc])\n",
        "gc.collect()\n",
        "\n",
        "trn=df.loc[:trn_s-1]\n",
        "tst=df.loc[trn_s:].reset_index(drop=True)\n",
        "del([df])\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2151.40 MB\n",
            "Memory usage after optimization is: 544.13 MB\n",
            "Decreased by 74.7%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxmq8JSOz6Hk"
      },
      "source": [
        "categorical=[str(i) for i in range(444)]\n",
        "trn[categorical]=trn[categorical].astype('uint8')\n",
        "tst[categorical]=tst[categorical].astype('uint8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVjoANI76nSZ"
      },
      "source": [
        "class stocasticensembling(Callback):\r\n",
        "  def __init__(self,model_name,alpha1,alpha2,iter_per_epoch,cycle_len,seqs_dict,start_inx=0,save_se_weights=False,folder='/content',**kwargs):\r\n",
        "    #save_se_weights: save after each epoch ?\r\n",
        "\r\n",
        "    super(stocasticensembling,self).__init__()\r\n",
        "    self.model_count=0\r\n",
        "    self.alpha1=alpha1\r\n",
        "    self.alpha2=alpha2\r\n",
        "    self.clr_iterations=0\r\n",
        "    self.cycle_num=cycle_len\r\n",
        "    self.cycle_len=cycle_len\r\n",
        "    self.iter_per_epoch=iter_per_epoch\r\n",
        "    self.iter_per_cycle = self.cycle_len * self.iter_per_epoch\r\n",
        "    self.save_se_weights=save_se_weights\r\n",
        "    self.start_inx=start_inx\r\n",
        "    self.swa_weights=[]\r\n",
        "    self.folder=folder\r\n",
        "    self.seqs_dict=seqs_dict\r\n",
        "    self.model_name=model_name\r\n",
        "    self.prob_dict={k: [] for k in self.seqs_dict.keys()}\r\n",
        "    self.lrs=[]\r\n",
        "\r\n",
        "  def on_train_end(self,logs={}):\r\n",
        "    self.weight_update()\r\n",
        "    self.model.set_weights(self.swa_weights)\r\n",
        "    self.snapsort()\r\n",
        "    for seq_names,probs in self.prob_dict.items():\r\n",
        "      self.prob_dict[seq_names]=np.concatenate(probs,axis=-1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_begin(self,epoch,logs=None):\r\n",
        "    self.current_epoch=epoch\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_end(self,epoch,logs=None):\r\n",
        "    self.cycle_num+=1\r\n",
        "    if (self._t_cycle() !=1) or (epoch == 15):\r\n",
        "      return\r\n",
        "    self.snapsort()\r\n",
        "    self.weight_update()\r\n",
        "    self.model_count+=1\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_batch_begin(self,batch,logs=None):\r\n",
        "    self.clr_iterations+=1\r\n",
        "    lr=self._clr_schedule()\r\n",
        "    self.lrs.append(lr)\r\n",
        "    K.set_value(self.model.optimizer.lr,lr)\r\n",
        "  \r\n",
        "  \r\n",
        "  def snapsort(self):\r\n",
        "    print(self.clr_iterations)\r\n",
        "    print(K.eval(self.model.optimizer.lr))\r\n",
        "    for seq_name,seq in self.seqs_dict.items():\r\n",
        "      self.prob_dict[seq_name].append(self.model.predict(seq,steps=len(seq)))\r\n",
        "  \r\n",
        "  \r\n",
        "  def weight_update(self):\r\n",
        "    weights=self.model.get_weights()\r\n",
        "    if self.model_count==0:\r\n",
        "      self.swa_weights=weights\r\n",
        "    for i in range(0,len(weights)):\r\n",
        "      self.swa_weights[i]=(self.swa_weights[i]*self.model_count+weights[i])/(self.model_count+1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def _t_cycle(self):\r\n",
        "        return (((self.clr_iterations - 1) % self.iter_per_cycle) + 1) / self.iter_per_cycle\r\n",
        "  \r\n",
        "  \r\n",
        "  def _clr_schedule(self):\r\n",
        "    return ((1.0 - 1.0 *self._t_cycle()) * self.alpha2) + (1.0 *self._t_cycle() *self.alpha1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oor5OujA6Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892ebf27-4b40-4892-8ee0-c98329907a8a"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "splits=KFold(n_splits=5)\n",
        "gc.collect()\n",
        "pre=np.zeros((506691,1))\n",
        "# tst=tst.drop(['isFraud'],1)\n",
        "for train_index,test_index in tqdm(splits.split(trn)):\n",
        "  X_train, X_test = trn.loc[train_index], trn.loc[test_index]\n",
        "  y_train, y_test = X_train['isFraud'], X_test['isFraud']\n",
        "  ids={}\n",
        "  for en,id in enumerate(X_train['id'].unique()):\n",
        "    ids[id]=en+2\n",
        "  X_train['id']=X_train['id'].map(lambda x: ids.get(x,1))\n",
        "  X_test['id']=X_test['id'].map(lambda x: ids.get(x,1))\n",
        "  dim=X_train['id'].nunique()+2\n",
        "  gc.collect()\n",
        "  trn_id,tst_id=X_train['id'],X_test['id']\n",
        "  X_train=X_train.drop(['isFraud','id'],1)\n",
        "  X_test=X_test.drop(['isFraud','id'],1)\n",
        "  seqs_dict={'test':[tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))]}\n",
        "  se = stocasticensembling(seqs_dict=seqs_dict, cycle_len=4, iter_per_epoch=231,\n",
        "                                  alpha1=5e-4, alpha2=5e-3,\n",
        "                                   model_name=\"model\", verbose=1)\n",
        "  mod=load_model(dim)\n",
        "  roc = RocCallback(validation_data=([X_test,tst_id], y_test),epochs=10)\n",
        "  mod.compile(optimizer=Nadam(),loss='binary_crossentropy')\n",
        "  es=EarlyStopping(monitor='acu_val',min_delta=0.0001,mode='min',restore_best_weights=True,patience=10)\n",
        "  mod.fit([X_train,trn_id],y_train,validation_data=([X_test,tst_id],y_test),batch_size=2048,epochs=16,callbacks=[se])\n",
        "  \n",
        "  del[(X_train,y_train)]\n",
        "  gc.collect()\n",
        "\n",
        "  mod.fit([X_test,tst_id],y_test,epochs=2,batch_size=2048)\n",
        "  pre+=se.prob_dict['test'].mean(1).reshape(506691,1)\n",
        "  pre+=mod.predict([tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))])\n",
        "\n",
        "  \n",
        "  del([X_test,y_test,mod])\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "231/231 [==============================] - 6s 19ms/step - loss: 0.1406 - val_loss: 0.0779\n",
            "Epoch 2/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0642 - val_loss: 0.0707\n",
            "Epoch 3/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0412 - val_loss: 0.0739\n",
            "Epoch 4/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0306 - val_loss: 0.0759\n",
            "924\n",
            "0.0005\n",
            "Epoch 5/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0275 - val_loss: 0.0791\n",
            "Epoch 6/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0167 - val_loss: 0.0912\n",
            "Epoch 7/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0124 - val_loss: 0.0884\n",
            "Epoch 8/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0100 - val_loss: 0.0843\n",
            "1848\n",
            "0.0005\n",
            "Epoch 9/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0104 - val_loss: 0.0935\n",
            "Epoch 10/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0088 - val_loss: 0.0988\n",
            "Epoch 11/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0074 - val_loss: 0.0948\n",
            "Epoch 12/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0065 - val_loss: 0.0931\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0072 - val_loss: 0.0863\n",
            "Epoch 14/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0069 - val_loss: 0.0826\n",
            "Epoch 15/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0060 - val_loss: 0.0951\n",
            "Epoch 16/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0053 - val_loss: 0.0881\n",
            "3696\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0588\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.0513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1it [01:51, 111.93s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "231/231 [==============================] - 6s 19ms/step - loss: 0.1306 - val_loss: 0.0977\n",
            "Epoch 2/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0617 - val_loss: 0.0805\n",
            "Epoch 3/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0393 - val_loss: 0.0767\n",
            "Epoch 4/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0291 - val_loss: 0.0772\n",
            "924\n",
            "0.0005\n",
            "Epoch 5/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0262 - val_loss: 0.0825\n",
            "Epoch 6/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0168 - val_loss: 0.0757\n",
            "Epoch 7/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0119 - val_loss: 0.0810\n",
            "Epoch 8/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0096 - val_loss: 0.0788\n",
            "1848\n",
            "0.0005\n",
            "Epoch 9/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0100 - val_loss: 0.0843\n",
            "Epoch 10/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0085 - val_loss: 0.0845\n",
            "Epoch 11/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0072 - val_loss: 0.0837\n",
            "Epoch 12/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0063 - val_loss: 0.0825\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0068 - val_loss: 0.0934\n",
            "Epoch 14/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0066 - val_loss: 0.0849\n",
            "Epoch 15/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0059 - val_loss: 0.0856\n",
            "Epoch 16/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0051 - val_loss: 0.0881\n",
            "3696\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.0697\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.0609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2it [03:44, 112.12s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "231/231 [==============================] - 6s 19ms/step - loss: 0.1493 - val_loss: 0.0919\n",
            "Epoch 2/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0647 - val_loss: 0.0781\n",
            "Epoch 3/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0408 - val_loss: 0.0751\n",
            "Epoch 4/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0305 - val_loss: 0.0746\n",
            "924\n",
            "0.0005\n",
            "Epoch 5/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0272 - val_loss: 0.0866\n",
            "Epoch 6/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0172 - val_loss: 0.0847\n",
            "Epoch 7/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0123 - val_loss: 0.0808\n",
            "Epoch 8/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0102 - val_loss: 0.0792\n",
            "1848\n",
            "0.0005\n",
            "Epoch 9/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0104 - val_loss: 0.0823\n",
            "Epoch 10/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0086 - val_loss: 0.0832\n",
            "Epoch 11/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0073 - val_loss: 0.0836\n",
            "Epoch 12/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0063 - val_loss: 0.0826\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0071 - val_loss: 0.0857\n",
            "Epoch 14/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0065 - val_loss: 0.0901\n",
            "Epoch 15/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0061 - val_loss: 0.0853\n",
            "Epoch 16/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0053 - val_loss: 0.0880\n",
            "3696\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0674\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "3it [05:37, 112.24s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "231/231 [==============================] - 6s 20ms/step - loss: 0.1256 - val_loss: 0.0900\n",
            "Epoch 2/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0631 - val_loss: 0.0758\n",
            "Epoch 3/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0403 - val_loss: 0.0703\n",
            "Epoch 4/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0301 - val_loss: 0.0693\n",
            "924\n",
            "0.0005\n",
            "Epoch 5/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0270 - val_loss: 0.0719\n",
            "Epoch 6/16\n",
            "231/231 [==============================] - 4s 16ms/step - loss: 0.0166 - val_loss: 0.0681\n",
            "Epoch 7/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0120 - val_loss: 0.0680\n",
            "Epoch 8/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0100 - val_loss: 0.0672\n",
            "1848\n",
            "0.0005\n",
            "Epoch 9/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0105 - val_loss: 0.0695\n",
            "Epoch 10/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0084 - val_loss: 0.0701\n",
            "Epoch 11/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0067 - val_loss: 0.0692\n",
            "Epoch 12/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0062 - val_loss: 0.0699\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0070 - val_loss: 0.0724\n",
            "Epoch 14/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0066 - val_loss: 0.0729\n",
            "Epoch 15/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0057 - val_loss: 0.0734\n",
            "Epoch 16/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0052 - val_loss: 0.0726\n",
            "3696\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.0652\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "4it [07:30, 112.47s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "231/231 [==============================] - 6s 19ms/step - loss: 0.1315 - val_loss: 0.0946\n",
            "Epoch 2/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0620 - val_loss: 0.0872\n",
            "Epoch 3/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0407 - val_loss: 0.0888\n",
            "Epoch 4/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0299 - val_loss: 0.0860\n",
            "924\n",
            "0.0005\n",
            "Epoch 5/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0270 - val_loss: 0.0936\n",
            "Epoch 6/16\n",
            "231/231 [==============================] - 4s 16ms/step - loss: 0.0168 - val_loss: 0.0880\n",
            "Epoch 7/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0127 - val_loss: 0.0918\n",
            "Epoch 8/16\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0100 - val_loss: 0.0930\n",
            "1848\n",
            "0.0005\n",
            "Epoch 9/16\n",
            "231/231 [==============================] - 4s 16ms/step - loss: 0.0106 - val_loss: 0.0949\n",
            "Epoch 10/16\n",
            "231/231 [==============================] - 4s 16ms/step - loss: 0.0087 - val_loss: 0.1001\n",
            "Epoch 11/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0074 - val_loss: 0.1007\n",
            "Epoch 12/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0064 - val_loss: 0.1009\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/16\n",
            "231/231 [==============================] - 4s 16ms/step - loss: 0.0071 - val_loss: 0.0935\n",
            "Epoch 14/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0067 - val_loss: 0.1114\n",
            "Epoch 15/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0061 - val_loss: 0.1071\n",
            "Epoch 16/16\n",
            "231/231 [==============================] - 4s 15ms/step - loss: 0.0056 - val_loss: 0.1050\n",
            "3696\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0714\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "5it [09:23, 112.67s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYgkVd5_NVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "34f5834a-af81-44e5-be1a-8f5f3f9f0555"
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv.zip')\n",
        "sub['isFraud']=pre.ravel()/10\n",
        "sub=sub.set_index('TransactionID')\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.000023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.015248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.001586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.001490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.000029\n",
              "3663550        0.000023\n",
              "3663551        0.015248\n",
              "3663552        0.001586\n",
              "3663553        0.001490"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZlw01oHayo"
      },
      "source": [
        "sub.to_csv('sub.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FeqwiR2HcSI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5d7c0794-e81f-43a3-c0eb-1956f1d5e932"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre/10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faef7040da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeWMkwJIWng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}