{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoenc_prep_with_id.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/autoenc_prep_with_id.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYtsrH0G_GC3",
        "colab_type": "text"
      },
      "source": [
        "Loading the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "6ec9cd90-9356-41d0-ac4b-94f5eeee5253"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo-8vK5m_NrM",
        "colab_type": "text"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRe81MJS_NUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from math import *\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam\n",
        "import gc\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "from keras.utils import Sequence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3CLKiyk_VTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "np.random.seed(42) # NumPy\n",
        "random.seed(42) # Python"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFkVLjyg_Io5",
        "colab_type": "text"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJem4-mp8otc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train_id.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test_id.csv',index_col=[0])\n",
        "categorical=[str(i) for i in range(444)]\n",
        "trn[categorical]=trn[categorical].astype('uint8')\n",
        "tst[categorical]=tst[categorical].astype('uint8')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk57wdug_Kuq",
        "colab_type": "text"
      },
      "source": [
        "Drop  isFraud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiE3LbOCCgku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e90041c0-2733-484a-f408-33818f2c4dca"
      },
      "source": [
        "trn=trn.drop(['isFraud'],1)\n",
        "trn.shape,tst.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((590540, 617), (506691, 617))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaSRatVa_Qlr",
        "colab_type": "text"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKYcx1CSuEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ead108e0-05cf-4604-8a7d-480853426027"
      },
      "source": [
        "\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1034.00 MB\n",
            "Memory usage after optimization is: 663.43 MB\n",
            "Decreased by 35.8%\n",
            "Memory usage of dataframe is 887.19 MB\n",
            "Memory usage after optimization is: 566.33 MB\n",
            "Decreased by 36.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYYe5k4-_aBP",
        "colab_type": "text"
      },
      "source": [
        "Concatenate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha_HXo738T8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5b93af53-4280-4ac6-ac39-abce4200e611"
      },
      "source": [
        "X=pd.concat([trn,tst]).reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "X[categorical]=X[categorical].astype('uint8')\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGUnUEl_dAz",
        "colab_type": "text"
      },
      "source": [
        "Divide data into categorical and numerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLml17V2_dJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cat=[str(i) for i in range(444)]\n",
        "X[cat]=X[cat].astype('uint8')\n",
        "no_dum=[i for i in X.columns if i not in cat]\n",
        "num_shape=len(no_dum)\n",
        "cat_shape=len(cat)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EskXmTJOPUZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIcL-BDLW9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gc.collect()\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "def create_model():\n",
        "    K.clear_session()\n",
        "    num_inp = Input(shape=(num_shape,))\n",
        "    cat_inp = Input(shape=(cat_shape,))\n",
        "    inps = concatenate([num_inp, cat_inp])\n",
        "    x = Dense(512, activation=custom_gelu)(inps)\n",
        "    x = Dense(256, activation=custom_gelu)(x)\n",
        "    x = Dense(512, activation = custom_gelu)(x)\n",
        "    x = Dropout(.2)(x)\n",
        "    cat_out = Dense(cat_shape, activation = \"linear\")(x)\n",
        "    num_out = Dense(num_shape, activation = \"linear\")(x)\n",
        "    model = Model(inputs=[num_inp,cat_inp], outputs=[num_out, cat_out])\n",
        "    model.compile(\n",
        "        optimizer=Adam(.05, clipnorm = 1, clipvalue = 1),\n",
        "        loss=[\"mse\", \"mse\"]\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWNV_5Kl_y46",
        "colab_type": "text"
      },
      "source": [
        "Warmup learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf25ibJI8T5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class WarmUpLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Warmup learning rate scheduler\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
        "        \"\"\"Constructor for warmup learning rate scheduler\n",
        "\n",
        "        Arguments:\n",
        "            warmup_batches {int} -- Number of batch for warmup.\n",
        "            init_lr {float} -- Learning rate after warmup.\n",
        "\n",
        "        Keyword Arguments:\n",
        "            verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
        "        \"\"\"\n",
        "\n",
        "        super(WarmUpLearningRateScheduler, self).__init__()\n",
        "        self.warmup_batches = warmup_batches\n",
        "        self.init_lr = init_lr\n",
        "        self.verbose = verbose\n",
        "        self.batch_count = 0\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_count = self.batch_count + 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        if self.batch_count <= self.warmup_batches:\n",
        "            lr = self.batch_count*self.init_lr/self.warmup_batches\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "            if self.verbose > 0:\n",
        "                print('\\nBatch %05d: WarmUpLearningRateScheduler setting learning '\n",
        "                      'rate to %s.' % (self.batch_count + 1, lr))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMkvG-As_4Pb",
        "colab_type": "text"
      },
      "source": [
        "Data generator for denoising autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyjXsW3U8Txj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class DAESequence(Sequence):\n",
        "    def __init__(self,df,no_dum,frac=0.15,dumm=range(911),batch_size=2048):\n",
        "        self.batch_size=batch_size\n",
        "        self.frac=0.15\n",
        "        self.dumm=dumm\n",
        "        self.df=df\n",
        "        self.cat_data=df[dumm].values\n",
        "        self.num_data=df[no_dum].values\n",
        "        self.no_dumm=no_dum\n",
        "        self.len_data=df.shape[0]\n",
        "        self.columns=df.shape[1]\n",
        "        self.data=df\n",
        "        self.idx=[]\n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(ceil(self.len_data/self.batch_size))\n",
        "    \n",
        "    \n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        self.idx.append(idx)\n",
        "        last=min((idx+1)*self.batch_size,self.len_data)\n",
        "        idx=idx*self.batch_size\n",
        "        size=last-idx\n",
        "        \n",
        "        \n",
        "        inps=[]\n",
        "        outs=[]\n",
        "        output_x=self.data.iloc[idx:last]\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        data=output_x[self.no_dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.no_dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=noise_x[frm,i]\n",
        "            \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        data=output_x[self.dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=noise_x[frm,i]\n",
        "        \n",
        "        \n",
        "        \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        return inps,outs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acDwaLOGACcP",
        "colab_type": "text"
      },
      "source": [
        "Fill nan by mean then by 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryHot0g1BwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a47894b2-e179-498b-c7fd-f5de224c63aa"
      },
      "source": [
        "\n",
        "a=X.isna().sum()\n",
        "a=a[a>0]\n",
        "cls=list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "  if col in cls:\n",
        "    X[col]=X[col].fillna(X[col].mean())\n",
        "a=X.isna().sum()\n",
        "a=a[a>0]\n",
        "cls=list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "  if col in cls:\n",
        "    X[col]=X[col].fillna(0)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 53.29it/s]\n",
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXdXM2kpNXgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "497a34bb-8ca9-4c34-96aa-73e5f46de318"
      },
      "source": [
        "\n",
        "model_mse = create_model()\n",
        "warm_up_lr = WarmUpLearningRateScheduler(400, init_lr=0.0005)\n",
        "gc.collect()\n",
        "epochs = 100\n",
        "batch_size=2048\n",
        "train_gen=DAESequence(X,no_dum,batch_size=batch_size,dumm=cat)\n",
        "hist = model_mse.fit_generator(train_gen, steps_per_epoch=len(X)//batch_size, epochs=epochs,\n",
        "                           verbose=1, workers=-1,\n",
        "                           use_multiprocessing=True,\n",
        "                              callbacks=[ warm_up_lr])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.2250 - dense_4_loss: 0.1935 - dense_3_loss: 0.0315\n",
            "Epoch 2/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0810 - dense_4_loss: 0.0670 - dense_3_loss: 0.0140\n",
            "Epoch 3/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0670 - dense_4_loss: 0.0559 - dense_3_loss: 0.0111\n",
            "Epoch 4/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0627 - dense_4_loss: 0.0527 - dense_3_loss: 0.0100\n",
            "Epoch 5/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0613 - dense_4_loss: 0.0518 - dense_3_loss: 0.0094\n",
            "Epoch 6/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0570 - dense_4_loss: 0.0477 - dense_3_loss: 0.0093\n",
            "Epoch 7/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0587 - dense_4_loss: 0.0495 - dense_3_loss: 0.0092\n",
            "Epoch 8/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0554 - dense_4_loss: 0.0467 - dense_3_loss: 0.0087\n",
            "Epoch 9/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0528 - dense_4_loss: 0.0442 - dense_3_loss: 0.0086\n",
            "Epoch 10/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0508 - dense_4_loss: 0.0423 - dense_3_loss: 0.0085\n",
            "Epoch 11/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0507 - dense_4_loss: 0.0422 - dense_3_loss: 0.0084\n",
            "Epoch 12/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0490 - dense_4_loss: 0.0409 - dense_3_loss: 0.0082\n",
            "Epoch 13/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0481 - dense_4_loss: 0.0399 - dense_3_loss: 0.0081\n",
            "Epoch 14/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0488 - dense_4_loss: 0.0406 - dense_3_loss: 0.0082\n",
            "Epoch 15/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0462 - dense_4_loss: 0.0383 - dense_3_loss: 0.0080\n",
            "Epoch 16/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0467 - dense_4_loss: 0.0387 - dense_3_loss: 0.0079\n",
            "Epoch 17/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0467 - dense_4_loss: 0.0388 - dense_3_loss: 0.0079\n",
            "Epoch 18/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0447 - dense_4_loss: 0.0370 - dense_3_loss: 0.0078\n",
            "Epoch 19/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0468 - dense_4_loss: 0.0389 - dense_3_loss: 0.0078\n",
            "Epoch 20/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0444 - dense_4_loss: 0.0366 - dense_3_loss: 0.0078\n",
            "Epoch 21/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0437 - dense_4_loss: 0.0361 - dense_3_loss: 0.0076\n",
            "Epoch 22/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0428 - dense_4_loss: 0.0352 - dense_3_loss: 0.0076\n",
            "Epoch 23/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0424 - dense_4_loss: 0.0349 - dense_3_loss: 0.0076\n",
            "Epoch 24/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0433 - dense_4_loss: 0.0358 - dense_3_loss: 0.0075\n",
            "Epoch 25/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0426 - dense_4_loss: 0.0351 - dense_3_loss: 0.0075\n",
            "Epoch 26/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0436 - dense_4_loss: 0.0361 - dense_3_loss: 0.0075\n",
            "Epoch 27/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0424 - dense_4_loss: 0.0349 - dense_3_loss: 0.0074\n",
            "Epoch 28/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0413 - dense_4_loss: 0.0340 - dense_3_loss: 0.0074\n",
            "Epoch 29/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0419 - dense_4_loss: 0.0345 - dense_3_loss: 0.0075\n",
            "Epoch 30/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0407 - dense_4_loss: 0.0334 - dense_3_loss: 0.0073\n",
            "Epoch 31/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0400 - dense_4_loss: 0.0327 - dense_3_loss: 0.0073\n",
            "Epoch 32/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0412 - dense_4_loss: 0.0339 - dense_3_loss: 0.0073\n",
            "Epoch 33/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0408 - dense_4_loss: 0.0336 - dense_3_loss: 0.0072\n",
            "Epoch 34/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0415 - dense_4_loss: 0.0343 - dense_3_loss: 0.0072\n",
            "Epoch 35/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0405 - dense_4_loss: 0.0334 - dense_3_loss: 0.0072\n",
            "Epoch 36/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0390 - dense_4_loss: 0.0318 - dense_3_loss: 0.0072\n",
            "Epoch 37/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0387 - dense_4_loss: 0.0316 - dense_3_loss: 0.0071\n",
            "Epoch 38/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0383 - dense_4_loss: 0.0312 - dense_3_loss: 0.0071\n",
            "Epoch 39/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0387 - dense_4_loss: 0.0316 - dense_3_loss: 0.0070\n",
            "Epoch 40/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0384 - dense_4_loss: 0.0314 - dense_3_loss: 0.0070\n",
            "Epoch 41/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0384 - dense_4_loss: 0.0313 - dense_3_loss: 0.0070\n",
            "Epoch 42/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0399 - dense_4_loss: 0.0329 - dense_3_loss: 0.0070\n",
            "Epoch 43/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0374 - dense_4_loss: 0.0304 - dense_3_loss: 0.0070\n",
            "Epoch 44/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0395 - dense_4_loss: 0.0326 - dense_3_loss: 0.0069\n",
            "Epoch 45/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0382 - dense_4_loss: 0.0312 - dense_3_loss: 0.0069\n",
            "Epoch 46/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0373 - dense_4_loss: 0.0303 - dense_3_loss: 0.0070\n",
            "Epoch 47/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0373 - dense_4_loss: 0.0304 - dense_3_loss: 0.0070\n",
            "Epoch 48/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0388 - dense_4_loss: 0.0319 - dense_3_loss: 0.0069\n",
            "Epoch 49/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0366 - dense_4_loss: 0.0298 - dense_3_loss: 0.0068\n",
            "Epoch 50/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0375 - dense_4_loss: 0.0307 - dense_3_loss: 0.0068\n",
            "Epoch 51/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0389 - dense_4_loss: 0.0321 - dense_3_loss: 0.0068\n",
            "Epoch 52/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0366 - dense_4_loss: 0.0299 - dense_3_loss: 0.0067\n",
            "Epoch 53/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0367 - dense_4_loss: 0.0299 - dense_3_loss: 0.0068\n",
            "Epoch 54/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0402 - dense_4_loss: 0.0335 - dense_3_loss: 0.0067\n",
            "Epoch 55/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0361 - dense_4_loss: 0.0295 - dense_3_loss: 0.0067\n",
            "Epoch 56/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0396 - dense_4_loss: 0.0329 - dense_3_loss: 0.0067\n",
            "Epoch 57/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0403 - dense_4_loss: 0.0336 - dense_3_loss: 0.0066\n",
            "Epoch 58/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0362 - dense_4_loss: 0.0295 - dense_3_loss: 0.0067\n",
            "Epoch 59/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0374 - dense_4_loss: 0.0307 - dense_3_loss: 0.0067\n",
            "Epoch 60/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0407 - dense_4_loss: 0.0340 - dense_3_loss: 0.0066\n",
            "Epoch 61/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0365 - dense_4_loss: 0.0299 - dense_3_loss: 0.0066\n",
            "Epoch 62/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0351 - dense_4_loss: 0.0286 - dense_3_loss: 0.0066\n",
            "Epoch 63/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0353 - dense_4_loss: 0.0288 - dense_3_loss: 0.0065\n",
            "Epoch 64/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0357 - dense_4_loss: 0.0292 - dense_3_loss: 0.0065\n",
            "Epoch 65/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0366 - dense_4_loss: 0.0299 - dense_3_loss: 0.0067\n",
            "Epoch 66/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0357 - dense_4_loss: 0.0292 - dense_3_loss: 0.0065\n",
            "Epoch 67/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0351 - dense_4_loss: 0.0286 - dense_3_loss: 0.0064\n",
            "Epoch 68/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0348 - dense_4_loss: 0.0283 - dense_3_loss: 0.0064\n",
            "Epoch 69/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0354 - dense_4_loss: 0.0289 - dense_3_loss: 0.0065\n",
            "Epoch 70/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0353 - dense_4_loss: 0.0288 - dense_3_loss: 0.0065\n",
            "Epoch 71/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0353 - dense_4_loss: 0.0289 - dense_3_loss: 0.0064\n",
            "Epoch 72/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0370 - dense_4_loss: 0.0306 - dense_3_loss: 0.0064\n",
            "Epoch 73/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0351 - dense_4_loss: 0.0287 - dense_3_loss: 0.0064\n",
            "Epoch 74/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0353 - dense_4_loss: 0.0289 - dense_3_loss: 0.0064\n",
            "Epoch 75/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0350 - dense_4_loss: 0.0286 - dense_3_loss: 0.0064\n",
            "Epoch 76/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0360 - dense_4_loss: 0.0296 - dense_3_loss: 0.0064\n",
            "Epoch 77/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0355 - dense_4_loss: 0.0291 - dense_3_loss: 0.0064\n",
            "Epoch 78/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0348 - dense_4_loss: 0.0285 - dense_3_loss: 0.0064\n",
            "Epoch 79/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0358 - dense_4_loss: 0.0295 - dense_3_loss: 0.0063\n",
            "Epoch 80/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0343 - dense_4_loss: 0.0279 - dense_3_loss: 0.0063\n",
            "Epoch 81/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0352 - dense_4_loss: 0.0289 - dense_3_loss: 0.0063\n",
            "Epoch 82/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0342 - dense_4_loss: 0.0279 - dense_3_loss: 0.0063\n",
            "Epoch 83/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0355 - dense_4_loss: 0.0292 - dense_3_loss: 0.0063\n",
            "Epoch 84/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0343 - dense_4_loss: 0.0280 - dense_3_loss: 0.0063\n",
            "Epoch 85/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0337 - dense_4_loss: 0.0274 - dense_3_loss: 0.0063\n",
            "Epoch 86/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0361 - dense_4_loss: 0.0298 - dense_3_loss: 0.0063\n",
            "Epoch 87/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0339 - dense_4_loss: 0.0276 - dense_3_loss: 0.0063\n",
            "Epoch 88/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0336 - dense_4_loss: 0.0273 - dense_3_loss: 0.0063\n",
            "Epoch 89/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0342 - dense_4_loss: 0.0279 - dense_3_loss: 0.0063\n",
            "Epoch 90/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0336 - dense_4_loss: 0.0274 - dense_3_loss: 0.0062\n",
            "Epoch 91/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0339 - dense_4_loss: 0.0276 - dense_3_loss: 0.0063\n",
            "Epoch 92/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0336 - dense_4_loss: 0.0274 - dense_3_loss: 0.0062\n",
            "Epoch 93/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0338 - dense_4_loss: 0.0276 - dense_3_loss: 0.0062\n",
            "Epoch 94/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0358 - dense_4_loss: 0.0295 - dense_3_loss: 0.0063\n",
            "Epoch 95/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0330 - dense_4_loss: 0.0268 - dense_3_loss: 0.0062\n",
            "Epoch 96/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0349 - dense_4_loss: 0.0287 - dense_3_loss: 0.0062\n",
            "Epoch 97/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0340 - dense_4_loss: 0.0278 - dense_3_loss: 0.0062\n",
            "Epoch 98/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0337 - dense_4_loss: 0.0275 - dense_3_loss: 0.0062\n",
            "Epoch 99/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0372 - dense_4_loss: 0.0309 - dense_3_loss: 0.0062\n",
            "Epoch 100/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0347 - dense_4_loss: 0.0285 - dense_3_loss: 0.0062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNx0SXIhhb0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "f64cfa3d-c192-45b7-c2ab-9638fada5233"
      },
      "source": [
        "mod=Model(inputs=model_mse.inputs,outputs=model_mse.layers[4].output)\n",
        "mod.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 173)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 444)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 617)          0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          316416      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 447,744\n",
            "Trainable params: 447,744\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdaDfCWm8pDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "fda4a6ff-4162-4b63-dcea-74a4f26952c2"
      },
      "source": [
        "\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f70703f4630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcTepLPKl3uE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "acf3e388-fab2-4122-eba9-0c72332ff844"
      },
      "source": [
        "pre=mod.predict([X[no_dum],X[cat]])\n",
        "pre.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1097231, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8qLYW28Rg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(pre).to_csv('/content/gdrive/My Drive/fraud/with_id.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7kGh-p9H_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}