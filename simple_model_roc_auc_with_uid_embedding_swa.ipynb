{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_roc_auc_with_uid_embedding_swa",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_roc_auc_with_uid_embedding_swa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAeHxBw8EEt"
      },
      "source": [
        "Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstQrkXM8Bz9"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IonOu6819IW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a99de3-a444-4844-b156-110de7e804fa"
      },
      "source": [
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 54.0MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 94% 49.0M/52.2M [00:00<00:00, 58.3MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 59.7MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 219MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 99% 58.0M/58.3M [00:00<00:00, 70.6MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 99.4MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 162MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvhOLFro71iv"
      },
      "source": [
        "loading drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6000da9-94ff-4e81-d79d-f2a15291d44e"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZi5I0Va7-Af"
      },
      "source": [
        "Loading dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "ff1d0f0f-1768-404f-cc70-674d0f0f466a"
      },
      "source": [
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train_id.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test_id.csv',index_col=[0])\n",
        "trn.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>C9_std_isna</th>\n",
              "      <th>C10_std_isna</th>\n",
              "      <th>C11_std_isna</th>\n",
              "      <th>C12_std_isna</th>\n",
              "      <th>C13_std_isna</th>\n",
              "      <th>C14_std_isna</th>\n",
              "      <th>D1_mean_isna</th>\n",
              "      <th>D1_std_isna</th>\n",
              "      <th>D2_mean_isna</th>\n",
              "      <th>D2_std_isna</th>\n",
              "      <th>D3_mean_isna</th>\n",
              "      <th>D3_std_isna</th>\n",
              "      <th>D4_mean_isna</th>\n",
              "      <th>D4_std_isna</th>\n",
              "      <th>D5_mean_isna</th>\n",
              "      <th>D5_std_isna</th>\n",
              "      <th>D6_mean_isna</th>\n",
              "      <th>D6_std_isna</th>\n",
              "      <th>D7_mean_isna</th>\n",
              "      <th>D7_std_isna</th>\n",
              "      <th>D8_mean_isna</th>\n",
              "      <th>D8_std_isna</th>\n",
              "      <th>D9_mean_isna</th>\n",
              "      <th>D9_std_isna</th>\n",
              "      <th>D10_mean_isna</th>\n",
              "      <th>D10_std_isna</th>\n",
              "      <th>D11_mean_isna</th>\n",
              "      <th>D11_std_isna</th>\n",
              "      <th>D12_mean_isna</th>\n",
              "      <th>D12_std_isna</th>\n",
              "      <th>D13_mean_isna</th>\n",
              "      <th>D13_std_isna</th>\n",
              "      <th>D14_mean_isna</th>\n",
              "      <th>D14_std_isna</th>\n",
              "      <th>D15_mean_isna</th>\n",
              "      <th>D15_std_isna</th>\n",
              "      <th>V1_mean_isna</th>\n",
              "      <th>V1_std_isna</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wnan315.013926-13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wgmail.com325.027551.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Woutlook.com330.046631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wyahoo.com476.018132-111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hgmail.com420.044971.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 619 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2  ...  V1_std_isna  isFraud                          id\n",
              "0  1.0  0.0  0.0  ...            1        0         Wnan315.013926-13.0\n",
              "1  1.0  0.0  0.0  ...            1        0      Wgmail.com325.027551.0\n",
              "2  1.0  0.0  0.0  ...            0        0    Woutlook.com330.046631.0\n",
              "3  1.0  0.0  0.0  ...            1        0  Wyahoo.com476.018132-111.0\n",
              "4  0.0  0.0  0.0  ...            1        0      Hgmail.com420.044971.0\n",
              "\n",
              "[5 rows x 619 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEIUFVW8iAC"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4af11c0-9eaf-4df8-ef67-a1ef93b14ce5"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2793.39 MB\n",
            "Memory usage after optimization is: 678.37 MB\n",
            "Decreased by 75.7%\n",
            "Memory usage of dataframe is 2392.90 MB\n",
            "Memory usage after optimization is: 580.09 MB\n",
            "Decreased by 75.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjn9ePhArDJ"
      },
      "source": [
        "trn=trn.replace([np.inf,-np.inf],np.nan)\n",
        "tst=tst.replace([np.inf,-np.inf],np.nan)\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRqrD6vz8ol6"
      },
      "source": [
        "Making the callbacks and loading model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW"
      },
      "source": [
        "dk={}\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data,epochs):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "        self.epochs=epochs\n",
        "        self.val=0\n",
        "        self.wts=[]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        if roc_val>self.val:\n",
        "          self.val=roc_val\n",
        "          self.epoch=10\n",
        "          self.wts=self.model.get_weights()\n",
        "        else:\n",
        "          self.epoch-=1\n",
        "        if self.epoch==0:\n",
        "          self.model.set_weights(self.wts)\n",
        "          self.model.stop_training = True\n",
        "        print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model(dim):\n",
        "  K.clear_session()\n",
        "\n",
        "\n",
        "  uid=Input((1,))\n",
        "  inp=Input((873,))\n",
        "  emb=Embedding(input_dim=dim,output_dim=4)(uid)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Concatenate()([emb,x])\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=[inp,uid],outputs=x)\n",
        "  return mod\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZH6xEokzPfj"
      },
      "source": [
        "Adding all datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZw0LXIzPG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64335bb-251f-4866-bab7-b566bf2a22c8"
      },
      "source": [
        "trn_s=trn.shape[0]\n",
        "df=pd.concat([trn,tst],0).reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "autoenc=pd.read_csv('/content/gdrive/My Drive/fraud/without_id.csv',index_col=[0])\n",
        "\n",
        "autoenc.columns=[i for i in range(444,444+autoenc.shape[1])]\n",
        "\n",
        "\n",
        "df=pd.concat([df,autoenc],1)\n",
        "df=reduce_mem_usage(df)\n",
        "del([autoenc])\n",
        "gc.collect()\n",
        "\n",
        "trn=df.loc[:trn_s-1]\n",
        "tst=df.loc[trn_s:].reset_index(drop=True)\n",
        "del([df])\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 3384.06 MB\n",
            "Memory usage after optimization is: 1783.79 MB\n",
            "Decreased by 47.3%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxmq8JSOz6Hk"
      },
      "source": [
        "categorical=[str(i) for i in range(444)]\n",
        "trn[categorical]=trn[categorical].astype('uint8')\n",
        "tst[categorical]=tst[categorical].astype('uint8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVXGvLePKR8T"
      },
      "source": [
        "def rac(y_true, y_pred):\n",
        "    \"\"\" ROC AUC Score.\n",
        "    Approximates the Area Under Curve score, using approximation based on\n",
        "    the Wilcoxon-Mann-Whitney U statistic.\n",
        "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
        "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
        "    Measures overall performance for a full range of threshold levels.\n",
        "    Arguments:\n",
        "        y_pred: `Tensor`. Predicted values.\n",
        "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(\"RocAucScore\"):\n",
        "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
        "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
        "        pos = tf.expand_dims(pos, 0)\n",
        "        neg = tf.expand_dims(neg, 1)\n",
        "        # original paper suggests performance is robust to exact parameter choice\n",
        "        gamma = 0.3\n",
        "        p     = 1.5\n",
        "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
        "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
        "        return tf.reduce_sum(tf.pow(-masked, p))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w55g3o_D_eYn"
      },
      "source": [
        "class stocasticensembling(Callback):\r\n",
        "  def __init__(self,model_name,alpha1,alpha2,iter_per_epoch,cycle_len,seqs_dict,start_inx=0,save_se_weights=False,folder='/content',**kwargs):\r\n",
        "    #save_se_weights: save after each epoch ?\r\n",
        "\r\n",
        "    super(stocasticensembling,self).__init__()\r\n",
        "    self.model_count=0\r\n",
        "    self.alpha1=alpha1\r\n",
        "    self.alpha2=alpha2\r\n",
        "    self.clr_iterations=0\r\n",
        "    self.cycle_num=cycle_len\r\n",
        "    self.cycle_len=cycle_len\r\n",
        "    self.iter_per_epoch=iter_per_epoch\r\n",
        "    self.iter_per_cycle = self.cycle_len * self.iter_per_epoch\r\n",
        "    self.save_se_weights=save_se_weights\r\n",
        "    self.start_inx=start_inx\r\n",
        "    self.swa_weights=[]\r\n",
        "    self.folder=folder\r\n",
        "    self.seqs_dict=seqs_dict\r\n",
        "    self.model_name=model_name\r\n",
        "    self.prob_dict={k: [] for k in self.seqs_dict.keys()}\r\n",
        "    self.lrs=[]\r\n",
        "\r\n",
        "  def on_train_end(self,logs={}):\r\n",
        "    self.weight_update()\r\n",
        "    self.model.set_weights(self.swa_weights)\r\n",
        "    self.snapsort()\r\n",
        "    for seq_names,probs in self.prob_dict.items():\r\n",
        "      self.prob_dict[seq_names]=np.concatenate(probs,axis=-1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_begin(self,epoch,logs=None):\r\n",
        "    self.current_epoch=epoch\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_end(self,epoch,logs=None):\r\n",
        "    self.cycle_num+=1\r\n",
        "    if (self._t_cycle() !=1) or (epoch == 14):\r\n",
        "      return\r\n",
        "    self.snapsort()\r\n",
        "    self.weight_update()\r\n",
        "    self.model_count+=1\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_batch_begin(self,batch,logs=None):\r\n",
        "    self.clr_iterations+=1\r\n",
        "    lr=self._clr_schedule()\r\n",
        "    self.lrs.append(lr)\r\n",
        "    K.set_value(self.model.optimizer.lr,lr)\r\n",
        "  \r\n",
        "  \r\n",
        "  def snapsort(self):\r\n",
        "    print(self.clr_iterations)\r\n",
        "    print(K.eval(self.model.optimizer.lr))\r\n",
        "    for seq_name,seq in self.seqs_dict.items():\r\n",
        "      self.prob_dict[seq_name].append(self.model.predict(seq,steps=len(seq)))\r\n",
        "  \r\n",
        "  \r\n",
        "  def weight_update(self):\r\n",
        "    weights=self.model.get_weights()\r\n",
        "    if self.model_count==0:\r\n",
        "      self.swa_weights=weights\r\n",
        "    for i in range(0,len(weights)):\r\n",
        "      self.swa_weights[i]=(self.swa_weights[i]*self.model_count+weights[i])/(self.model_count+1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def _t_cycle(self):\r\n",
        "        return (((self.clr_iterations - 1) % self.iter_per_cycle) + 1) / self.iter_per_cycle\r\n",
        "  \r\n",
        "  \r\n",
        "  def _clr_schedule(self):\r\n",
        "    return ((1.0 - 1.0 *self._t_cycle()) * self.alpha2) + (1.0 *self._t_cycle() *self.alpha1)\r\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oor5OujA6Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b89d340-a57f-4f13-d873-2731cbef3cc6"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from matplotlib import pyplot as plt\n",
        "splits=KFold(n_splits=5)\n",
        "gc.collect()\n",
        "pre=np.zeros((506691,1))\n",
        "# tst=tst.drop(['isFraud'],1)\n",
        "for train_index,test_index in tqdm(splits.split(trn)):\n",
        "  X_train, X_test = trn.loc[train_index], trn.loc[test_index]\n",
        "  y_train, y_test = X_train['isFraud'], X_test['isFraud']\n",
        "  ids={}\n",
        "  for en,id in enumerate(X_train['id'].unique()):\n",
        "    ids[id]=en+2\n",
        "  X_train['id']=X_train['id'].map(lambda x: ids.get(x,1))\n",
        "  X_test['id']=X_test['id'].map(lambda x: ids.get(x,1))\n",
        "  dim=X_train['id'].nunique()+2\n",
        "  gc.collect()\n",
        "  trn_id,tst_id=X_train['id'],X_test['id']\n",
        "  X_train=X_train.drop(['isFraud','id'],1)\n",
        "  X_test=X_test.drop(['isFraud','id'],1)\n",
        "  mod=load_model(dim)\n",
        "  roc = RocCallback(validation_data=([X_test,tst_id], y_test),epochs=10)\n",
        "  mod.compile(optimizer=Nadam(),loss=rac)\n",
        "  es=EarlyStopping(monitor='acu_val',min_delta=0.0001,mode='min',restore_best_weights=True,patience=10)\n",
        "  seqs_dict={'test':[tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))]}\n",
        "  se = stocasticensembling(seqs_dict=seqs_dict, cycle_len=3, iter_per_epoch=231,\n",
        "                                  alpha1=5e-4, alpha2=5e-3,\n",
        "                                   model_name=\"model\", verbose=1)\n",
        "  mod.fit([X_train,trn_id],y_train,validation_data=([X_test,tst_id],y_test),batch_size=2048,epochs=15,callbacks=[se])\n",
        "  \n",
        "  del[(X_train,y_train)]\n",
        "  gc.collect()\n",
        "\n",
        "  mod.fit([X_test,tst_id],y_test,epochs=2,batch_size=2048)\n",
        "  pre+=se.prob_dict['test'].mean(1).reshape(506691,1)\n",
        "  pre+=mod.predict([tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))])\n",
        "\n",
        "  del([X_test,y_test,mod])\n",
        "  gc.collect()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 15ms/step - loss: 11917.3918 - val_loss: 4672.8374\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 1877.7261 - val_loss: 3998.3538\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 494.6341 - val_loss: 4418.2944\n",
            "693\n",
            "0.0005\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 325.9377 - val_loss: 4081.5388\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 123.6502 - val_loss: 4283.8096\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 93.7914 - val_loss: 4212.1362\n",
            "1386\n",
            "0.0005\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 102.2885 - val_loss: 3932.3896\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 67.2759 - val_loss: 4084.1804\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 58.1080 - val_loss: 3904.3428\n",
            "2079\n",
            "0.0005\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 66.7645 - val_loss: 3874.1702\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 50.2378 - val_loss: 3755.8354\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 40.9713 - val_loss: 3820.4045\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 48.1718 - val_loss: 3696.3264\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 2s 11ms/step - loss: 46.7304 - val_loss: 3589.6670\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 32.1443 - val_loss: 3613.5059\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2837.8499\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2213.2722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1it [01:30, 90.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 15ms/step - loss: 10589.1114 - val_loss: 5579.2456\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 2053.1619 - val_loss: 5141.3257\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 458.7430 - val_loss: 5323.4272\n",
            "693\n",
            "0.0005\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 280.8800 - val_loss: 4995.0220\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 106.0704 - val_loss: 5447.0098\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 81.1426 - val_loss: 5190.4487\n",
            "1386\n",
            "0.0005\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 72.5791 - val_loss: 5019.2324\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 63.0209 - val_loss: 4942.1084\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 55.9639 - val_loss: 4972.3579\n",
            "2079\n",
            "0.0005\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 54.2827 - val_loss: 4830.7505\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 43.8112 - val_loss: 4554.0630\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 38.5765 - val_loss: 4572.9775\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 42.8141 - val_loss: 4592.1685\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 36.2388 - val_loss: 4548.7744\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 32.3253 - val_loss: 4603.1562\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 3366.2393\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2625.5623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2it [03:01, 90.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 16ms/step - loss: 10837.6851 - val_loss: 5409.4199\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 2051.4999 - val_loss: 4797.4175\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 509.0772 - val_loss: 5344.2954\n",
            "693\n",
            "0.0005\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 335.3383 - val_loss: 5008.0454\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 129.0878 - val_loss: 4894.1860\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 90.1144 - val_loss: 4953.2891\n",
            "1386\n",
            "0.0005\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 88.6960 - val_loss: 4768.5718\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 70.2434 - val_loss: 4609.8320\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 53.3687 - val_loss: 4522.9487\n",
            "2079\n",
            "0.0005\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 63.3706 - val_loss: 4407.2827\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 51.2906 - val_loss: 4262.7925\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 41.1382 - val_loss: 4333.1758\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 44.9059 - val_loss: 4087.2158\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 38.6307 - val_loss: 4372.8003\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 31.2977 - val_loss: 4347.9404\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3362.0837\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2602.4197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3it [04:32, 90.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 15ms/step - loss: 10627.5328 - val_loss: 5044.2910\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 1983.5920 - val_loss: 4072.0657\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 569.1912 - val_loss: 4484.0547\n",
            "693\n",
            "0.0005\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 317.1875 - val_loss: 4795.0820\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 120.1617 - val_loss: 4524.7529\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 87.1849 - val_loss: 4311.1860\n",
            "1386\n",
            "0.0005\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 86.0554 - val_loss: 4200.5010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 65.1130 - val_loss: 4211.7280\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 49.2172 - val_loss: 3926.4160\n",
            "2079\n",
            "0.0005\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 51.2224 - val_loss: 3747.9985\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 46.5296 - val_loss: 3815.4150\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 36.3527 - val_loss: 3777.7856\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 41.0391 - val_loss: 3724.2051\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 2s 11ms/step - loss: 39.0910 - val_loss: 3614.6912\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 29.3730 - val_loss: 3658.7991\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2853.2102\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2297.8320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4it [06:03, 90.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 15ms/step - loss: 10635.2662 - val_loss: 5767.4512\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 2015.7560 - val_loss: 4965.1045\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 537.5021 - val_loss: 5192.3662\n",
            "693\n",
            "0.0005\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 349.3387 - val_loss: 5285.2412\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 125.7531 - val_loss: 4920.6489\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 88.9390 - val_loss: 5019.4072\n",
            "1386\n",
            "0.0005\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 96.2338 - val_loss: 4725.1929\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 79.5287 - val_loss: 4910.5400\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 56.3581 - val_loss: 4677.8643\n",
            "2079\n",
            "0.0005\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 62.2818 - val_loss: 4764.0513\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 56.3336 - val_loss: 4670.4365\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 44.0839 - val_loss: 4540.5347\n",
            "2772\n",
            "0.0005\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 46.6520 - val_loss: 4454.3184\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 40.7931 - val_loss: 4491.7241\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 11ms/step - loss: 33.7706 - val_loss: 4576.8950\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3593.7070\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2808.2756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5it [07:34, 90.83s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL1HvlFBHDyP",
        "outputId": "f2de2c20-0b3e-492c-b2d2-0bba1f3f247d"
      },
      "source": [
        "np.max(pre)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.998870491981506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYgkVd5_NVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "78a81fc9-feb6-46f3-eeb8-5df50a28d60c"
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv.zip')\n",
        "sub['isFraud']=pre/10\n",
        "sub=sub.set_index('TransactionID')\n",
        "sub.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.087487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.133419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.243877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.204592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.287255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.087487\n",
              "3663550        0.133419\n",
              "3663551        0.243877\n",
              "3663552        0.204592\n",
              "3663553        0.287255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZlw01oHayo"
      },
      "source": [
        "sub.to_csv('sub.csv')"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FeqwiR2HcSI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b1874998-4615-4540-97ff-b3f757f951e0"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre/10)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24a5b39f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MroLdHR2HkBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}