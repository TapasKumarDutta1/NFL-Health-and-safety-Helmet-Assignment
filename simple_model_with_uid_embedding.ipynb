{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_with_uid_embedding",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_with_uid_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAeHxBw8EEt"
      },
      "source": [
        "Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstQrkXM8Bz9"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IonOu6819IW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6043725-a3e6-47cb-b13b-bd5ba21d6ff8"
      },
      "source": [
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 77% 40.0M/52.2M [00:00<00:00, 93.4MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 106MB/s] \n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 29.6MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 57% 33.0M/58.3M [00:00<00:00, 79.3MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 132MB/s] \n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 216MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 78.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvhOLFro71iv"
      },
      "source": [
        "loading drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408e6bcf-f560-42c3-b4dc-4f9abfc2bc0f"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZi5I0Va7-Af"
      },
      "source": [
        "Loading dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "e8e5e8fa-e630-4efb-cf78-a19636675b51"
      },
      "source": [
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train_id.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test_id.csv',index_col=[0])\n",
        "trn.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>C9_std_isna</th>\n",
              "      <th>C10_std_isna</th>\n",
              "      <th>C11_std_isna</th>\n",
              "      <th>C12_std_isna</th>\n",
              "      <th>C13_std_isna</th>\n",
              "      <th>C14_std_isna</th>\n",
              "      <th>D1_mean_isna</th>\n",
              "      <th>D1_std_isna</th>\n",
              "      <th>D2_mean_isna</th>\n",
              "      <th>D2_std_isna</th>\n",
              "      <th>D3_mean_isna</th>\n",
              "      <th>D3_std_isna</th>\n",
              "      <th>D4_mean_isna</th>\n",
              "      <th>D4_std_isna</th>\n",
              "      <th>D5_mean_isna</th>\n",
              "      <th>D5_std_isna</th>\n",
              "      <th>D6_mean_isna</th>\n",
              "      <th>D6_std_isna</th>\n",
              "      <th>D7_mean_isna</th>\n",
              "      <th>D7_std_isna</th>\n",
              "      <th>D8_mean_isna</th>\n",
              "      <th>D8_std_isna</th>\n",
              "      <th>D9_mean_isna</th>\n",
              "      <th>D9_std_isna</th>\n",
              "      <th>D10_mean_isna</th>\n",
              "      <th>D10_std_isna</th>\n",
              "      <th>D11_mean_isna</th>\n",
              "      <th>D11_std_isna</th>\n",
              "      <th>D12_mean_isna</th>\n",
              "      <th>D12_std_isna</th>\n",
              "      <th>D13_mean_isna</th>\n",
              "      <th>D13_std_isna</th>\n",
              "      <th>D14_mean_isna</th>\n",
              "      <th>D14_std_isna</th>\n",
              "      <th>D15_mean_isna</th>\n",
              "      <th>D15_std_isna</th>\n",
              "      <th>V1_mean_isna</th>\n",
              "      <th>V1_std_isna</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wnan315.013926-13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wgmail.com325.027551.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Woutlook.com330.046631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wyahoo.com476.018132-111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hgmail.com420.044971.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 619 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2  ...  V1_std_isna  isFraud                          id\n",
              "0  1.0  0.0  0.0  ...            1        0         Wnan315.013926-13.0\n",
              "1  1.0  0.0  0.0  ...            1        0      Wgmail.com325.027551.0\n",
              "2  1.0  0.0  0.0  ...            0        0    Woutlook.com330.046631.0\n",
              "3  1.0  0.0  0.0  ...            1        0  Wyahoo.com476.018132-111.0\n",
              "4  0.0  0.0  0.0  ...            1        0      Hgmail.com420.044971.0\n",
              "\n",
              "[5 rows x 619 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEIUFVW8iAC"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e248f5-1464-4ace-919a-e28ac9a4234e"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2793.39 MB\n",
            "Memory usage after optimization is: 678.37 MB\n",
            "Decreased by 75.7%\n",
            "Memory usage of dataframe is 2392.90 MB\n",
            "Memory usage after optimization is: 580.09 MB\n",
            "Decreased by 75.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjn9ePhArDJ"
      },
      "source": [
        "trn=trn.replace([np.inf,-np.inf],np.nan)\n",
        "tst=tst.replace([np.inf,-np.inf],np.nan)\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRqrD6vz8ol6"
      },
      "source": [
        "Making the callbacks and loading model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW"
      },
      "source": [
        "dk={}\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data,epochs):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "        self.epochs=epochs\n",
        "        self.val=0\n",
        "        self.wts=[]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        if roc_val>self.val:\n",
        "          self.val=roc_val\n",
        "          self.epoch=10\n",
        "          self.wts=self.model.get_weights()\n",
        "        else:\n",
        "          self.epoch-=1\n",
        "        if self.epoch==0:\n",
        "          self.model.set_weights(self.wts)\n",
        "          self.model.stop_training = True\n",
        "        print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model(dim):\n",
        "  K.clear_session()\n",
        "\n",
        "\n",
        "  uid=Input((1,))\n",
        "  inp=Input((873,))\n",
        "  emb=Embedding(input_dim=dim,output_dim=4)(uid)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Concatenate()([emb,x])\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=[inp,uid],outputs=x)\n",
        "  return mod\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZH6xEokzPfj"
      },
      "source": [
        "Adding all datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZw0LXIzPG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56297213-89fd-47e6-a391-118db2f4e831"
      },
      "source": [
        "trn_s=trn.shape[0]\n",
        "df=pd.concat([trn,tst],0).reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "autoenc=pd.read_csv('/content/gdrive/My Drive/fraud/without_id.csv',index_col=[0])\n",
        "autoenc=reduce_mem_usage(autoenc)\n",
        "\n",
        "autoenc.columns=[i for i in range(444,444+autoenc.shape[1])]\n",
        "\n",
        "\n",
        "df=pd.concat([df,autoenc],1)\n",
        "del([autoenc])\n",
        "gc.collect()\n",
        "\n",
        "trn=df.loc[:trn_s-1]\n",
        "tst=df.loc[trn_s:].reset_index(drop=True)\n",
        "del([df])\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2151.40 MB\n",
            "Memory usage after optimization is: 544.13 MB\n",
            "Decreased by 74.7%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxmq8JSOz6Hk"
      },
      "source": [
        "categorical=[str(i) for i in range(444)]\n",
        "trn[categorical]=trn[categorical].astype('uint8')\n",
        "tst[categorical]=tst[categorical].astype('uint8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvGV_22v6leh"
      },
      "source": [
        "class stocasticensembling(Callback):\r\n",
        "  def __init__(self,model_name,alpha1,alpha2,iter_per_epoch,cycle_len,seqs_dict,start_inx=0,save_se_weights=False,folder='/content',**kwargs):\r\n",
        "    #save_se_weights: save after each epoch ?\r\n",
        "\r\n",
        "    super(stocasticensembling,self).__init__()\r\n",
        "    self.model_count=0\r\n",
        "    self.alpha1=alpha1\r\n",
        "    self.alpha2=alpha2\r\n",
        "    self.clr_iterations=0\r\n",
        "    self.cycle_num=cycle_len\r\n",
        "    self.cycle_len=cycle_len\r\n",
        "    self.iter_per_epoch=iter_per_epoch\r\n",
        "    self.iter_per_cycle = self.cycle_len * self.iter_per_epoch\r\n",
        "    self.save_se_weights=save_se_weights\r\n",
        "    self.start_inx=start_inx\r\n",
        "    self.swa_weights=[]\r\n",
        "    self.folder=folder\r\n",
        "    self.seqs_dict=seqs_dict\r\n",
        "    self.model_name=model_name\r\n",
        "    self.prob_dict={k: [] for k in self.seqs_dict.keys()}\r\n",
        "    self.lrs=[]\r\n",
        "\r\n",
        "  def on_train_end(self,logs={}):\r\n",
        "    self.weight_update()\r\n",
        "    self.model.set_weights(self.swa_weights)\r\n",
        "    self.snapsort()\r\n",
        "    for seq_names,probs in self.prob_dict.items():\r\n",
        "      self.prob_dict[seq_names]=np.concatenate(probs,axis=-1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_begin(self,epoch,logs=None):\r\n",
        "    self.current_epoch=epoch\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_epoch_end(self,epoch,logs=None):\r\n",
        "    self.cycle_num+=1\r\n",
        "    if (self._t_cycle() !=1) or (epoch == 14):\r\n",
        "      return\r\n",
        "    self.snapsort()\r\n",
        "    self.weight_update()\r\n",
        "    self.model_count+=1\r\n",
        "  \r\n",
        "  \r\n",
        "  def on_batch_begin(self,batch,logs=None):\r\n",
        "    self.clr_iterations+=1\r\n",
        "    lr=self._clr_schedule()\r\n",
        "    self.lrs.append(lr)\r\n",
        "    K.set_value(self.model.optimizer.lr,lr)\r\n",
        "  \r\n",
        "  \r\n",
        "  def snapsort(self):\r\n",
        "    print(self.clr_iterations)\r\n",
        "    print(K.eval(self.model.optimizer.lr))\r\n",
        "    for seq_name,seq in self.seqs_dict.items():\r\n",
        "      self.prob_dict[seq_name].append(self.model.predict(seq,steps=len(seq)))\r\n",
        "  \r\n",
        "  \r\n",
        "  def weight_update(self):\r\n",
        "    weights=self.model.get_weights()\r\n",
        "    if self.model_count==0:\r\n",
        "      self.swa_weights=weights\r\n",
        "    for i in range(0,len(weights)):\r\n",
        "      self.swa_weights[i]=(self.swa_weights[i]*self.model_count+weights[i])/(self.model_count+1)\r\n",
        "  \r\n",
        "  \r\n",
        "  def _t_cycle(self):\r\n",
        "        return (((self.clr_iterations - 1) % self.iter_per_cycle) + 1) / self.iter_per_cycle\r\n",
        "  \r\n",
        "  \r\n",
        "  def _clr_schedule(self):\r\n",
        "    return ((1.0 - 1.0 *self._t_cycle()) * self.alpha2) + (1.0 *self._t_cycle() *self.alpha1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oor5OujA6Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28dbdae5-19af-4ec2-aaa1-17325b52431c"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "splits=KFold(n_splits=5)\n",
        "gc.collect()\n",
        "pre=np.zeros((506691,1))\n",
        "# tst=tst.drop(['isFraud'],1)\n",
        "for train_index,test_index in tqdm(splits.split(trn)):\n",
        "  X_train, X_test = trn.loc[train_index], trn.loc[test_index]\n",
        "  y_train, y_test = X_train['isFraud'], X_test['isFraud']\n",
        "  ids={}\n",
        "  for en,id in enumerate(X_train['id'].unique()):\n",
        "    ids[id]=en+2\n",
        "  X_train['id']=X_train['id'].map(lambda x: ids.get(x,1))\n",
        "  X_test['id']=X_test['id'].map(lambda x: ids.get(x,1))\n",
        "  dim=X_train['id'].nunique()+2\n",
        "  gc.collect()\n",
        "  trn_id,tst_id=X_train['id'],X_test['id']\n",
        "  X_train=X_train.drop(['isFraud','id'],1)\n",
        "  X_test=X_test.drop(['isFraud','id'],1)\n",
        "  seqs_dict={'test':[tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))]}\n",
        "  se = stocasticensembling(seqs_dict=seqs_dict, cycle_len=5, iter_per_epoch=231,\n",
        "                                  alpha1=5e-4, alpha2=5e-3,\n",
        "                                   model_name=\"model\", verbose=1)\n",
        "  mod=load_model(dim)\n",
        "  roc = RocCallback(validation_data=([X_test,tst_id], y_test),epochs=10)\n",
        "  mod.compile(optimizer=Nadam(),loss='binary_crossentropy')\n",
        "  es=EarlyStopping(monitor='acu_val',min_delta=0.0001,mode='min',restore_best_weights=True,patience=10)\n",
        "  mod.fit([X_train,trn_id],y_train,validation_data=([X_test,tst_id],y_test),batch_size=2048,epochs=15,callbacks=[se])\n",
        "  \n",
        "  del[(X_train,y_train)]\n",
        "  gc.collect()\n",
        "\n",
        "  mod.fit([X_test,tst_id],y_test,epochs=2,batch_size=2048)\n",
        "  pre+=se.prob_dict['test'].mean(1).reshape(506691,1)\n",
        "  pre+=mod.predict([tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))])\n",
        "\n",
        "  \n",
        "  del([X_test,y_test,mod])\n",
        "  gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 17ms/step - loss: 0.1335 - val_loss: 0.0800\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0641 - val_loss: 0.0710\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0391 - val_loss: 0.0836\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0270 - val_loss: 0.0732\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0212 - val_loss: 0.0830\n",
            "1155\n",
            "0.0005\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0199 - val_loss: 0.0825\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0133 - val_loss: 0.0825\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0798\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0084 - val_loss: 0.0817\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0072 - val_loss: 0.0775\n",
            "2310\n",
            "0.0005\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0080 - val_loss: 0.0874\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0074 - val_loss: 0.0977\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0067 - val_loss: 0.0844\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0058 - val_loss: 0.0904\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0055 - val_loss: 0.0824\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0594\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1it [01:45, 105.47s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 6s 19ms/step - loss: 0.1279 - val_loss: 0.0890\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0611 - val_loss: 0.0800\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0371 - val_loss: 0.0773\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0260 - val_loss: 0.0759\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0203 - val_loss: 0.0744\n",
            "1155\n",
            "0.0005\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0193 - val_loss: 0.0770\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0133 - val_loss: 0.0778\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0098 - val_loss: 0.0760\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0082 - val_loss: 0.0780\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0072 - val_loss: 0.0763\n",
            "2310\n",
            "0.0005\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0079 - val_loss: 0.0785\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0076 - val_loss: 0.0802\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0066 - val_loss: 0.0815\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0056 - val_loss: 0.0810\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0051 - val_loss: 0.0809\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0704\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2it [03:30, 105.27s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 17ms/step - loss: 0.1306 - val_loss: 0.0910\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0619 - val_loss: 0.0800\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0373 - val_loss: 0.0761\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0268 - val_loss: 0.0745\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0209 - val_loss: 0.0748\n",
            "1155\n",
            "0.0005\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0203 - val_loss: 0.0849\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0134 - val_loss: 0.0799\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0789\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0071 - val_loss: 0.0813\n",
            "2310\n",
            "0.0005\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0081 - val_loss: 0.0878\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 15ms/step - loss: 0.0075 - val_loss: 0.0883\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0066 - val_loss: 0.0842\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0057 - val_loss: 0.0894\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0053 - val_loss: 0.0868\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0673\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "3it [05:09, 103.40s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 19ms/step - loss: 0.1396 - val_loss: 0.0881\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0622 - val_loss: 0.0762\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0390 - val_loss: 0.0703\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0267 - val_loss: 0.0713\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0207 - val_loss: 0.0714\n",
            "1155\n",
            "0.0005\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0196 - val_loss: 0.0722\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0133 - val_loss: 0.0758\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0730\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0081 - val_loss: 0.0728\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0072 - val_loss: 0.0730\n",
            "2310\n",
            "0.0005\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0077 - val_loss: 0.0737\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0070 - val_loss: 0.0774\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0064 - val_loss: 0.0784\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0058 - val_loss: 0.0790\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0052 - val_loss: 0.0778\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0649\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "4it [06:47, 101.94s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 17ms/step - loss: 0.1346 - val_loss: 0.0947\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0616 - val_loss: 0.0817\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0377 - val_loss: 0.0818\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0265 - val_loss: 0.0818\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0209 - val_loss: 0.0825\n",
            "1155\n",
            "0.0005\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0202 - val_loss: 0.0882\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0136 - val_loss: 0.0905\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0099 - val_loss: 0.0911\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0083 - val_loss: 0.0844\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0076 - val_loss: 0.0910\n",
            "2310\n",
            "0.0005\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0081 - val_loss: 0.1069\n",
            "Epoch 12/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0075 - val_loss: 0.1007\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0065 - val_loss: 0.0946\n",
            "Epoch 14/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0060 - val_loss: 0.1002\n",
            "Epoch 15/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0053 - val_loss: 0.0951\n",
            "3465\n",
            "0.0005\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0709\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "5it [08:24, 100.83s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYgkVd5_NVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "89c6582f-4eca-49de-f76c-ac66f078eb45"
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv.zip')\n",
        "sub['isFraud']=pre.ravel()/10\n",
        "sub=sub.set_index('TransactionID')\n",
        "sub.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.000038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.000027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.004646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.002502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.002396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.000038\n",
              "3663550        0.000027\n",
              "3663551        0.004646\n",
              "3663552        0.002502\n",
              "3663553        0.002396"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZlw01oHayo"
      },
      "source": [
        "sub.to_csv('sub.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FeqwiR2HcSI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1c937086-ebef-4739-cf0d-11a83e344e56"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre/10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1e8381ef60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeWMkwJIWng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}